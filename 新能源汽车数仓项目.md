# 新能源汽车数仓项目

实验目的：收集汽车传感器的数据，由此分析出汽车是否出现了问题。



## 一.项目需求

- 业务数据采集平台的搭建
- 数据仓库维度建模
- 分析技术核心数据，统计报表
- 及时查询，随时指标分析
- 对集群性能进行监控，发生异常需要报警
- 元数据管理
- 质量监控
- 权限管理





## 二.模板虚拟机的搭建

 **安装模板虚拟机，IP地址 192.168.10.100、主机名称hadoop100、内存 4G、硬盘 50G**

参考博客：

https://blog.csdn.net/qq_43774324/article/details/125014162



- 安装 epel-release

```
[root@hadoop100 ~]# yum install -y epel-release
```



**如果Linux 安装的是最小系统版，还需要安装如下工具；如果安装的是 Linux桌面标准版，不需要执行如下操作**

```
[root@hadoop100 ~]# yum install -y net-tools 
[root@hadoop100 ~]# yum install -y vim
```



- **关闭防火墙，关闭防火墙开机自启**

```
[root@hadoop100 ~]# systemctl stop firewalld
[root@hadoop100 ~]# systemctl disable firewalld.service
```



- **创建  用户，并修改 atguigu 用户的密码**（可选）

```
[root@hadoop100 ~]# useradd XXX
[root@hadoop100 ~]# passwd XXX
```

当然名字自取，我这里取的是lchen



- **配置**用户具有root权限，方便后期加 **sudo** **执行** **root** **权限的命令**

  首先进入管理员权限： su root   密码：123456

  在%wheel 这行下面添加一行，如下所示：

```
[root@hadoop100 ~]# vim /etc/sudoers
```

```
## Allow root to run any commands anywhere
root ALL=(ALL) ALL
## Allows people in group wheel to run all commands
%wheel ALL=(ALL) ALL
atguigu ALL=(ALL) NOPASSWD:ALL
```

现在用户就有管理员权限了。

退出保存：wq!



- **在/opt 目录下创建文件夹**

```
[root@hadoop100 ~]# mkdir /opt/module
[root@hadoop100 ~]# mkdir /opt/software
```



- **卸载虚拟机自带的 JDK**

```
[root@hadoop100 ~]# rpm -qa | grep -i java | xargs -n1 rpm -e --nodeps
```

rpm -qa：查询所安装的所有rpm 软件包

grep -i：忽略大小写

xargs -n1：表示每次只传递一个参数

rpm -e –nodeps：强制卸载软件

查看是否还有JDK：

```
 rpm -qa | grep java
```



- 重启虚拟机

```
reboot   
```







## 三.环境准备

### （1）机器准备

#### 1.克隆三台模拟机

右击模板机（保证虚拟机关闭）——管理——克隆，在这一步选择“完整克隆”。其他全部点击“下一步”：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230714201010766.png" alt="image-20230714201010766" style="zoom: 33%;" />

以此类推，复制三台。





#### 2.修改主机名【3台都是一样的操作】

依次启动102，103，104机器，注意是——一个一个设置。（不能同时开启）

首先切换root用户：su root

修改主机名：（修改完:wq退出即可）

```
vim /etc/hostname
```

配置Linux 克隆机主机名称映射 hosts 文件：

```
[root@hadoop100 ~]# vim /etc/hosts
```

添加如下内容：

```
192.168.10.100 hadoop100
192.168.10.101 hadoop101
192.168.10.102 hadoop102
192.168.10.103 hadoop103
192.168.10.104 hadoop104
192.168.10.105 hadoop105
192.168.10.106 hadoop106
192.168.10.107 hadoop107
192.168.10.108 hadoop108
```

其中：192.168.10.100（第一列是网卡配置）**[我们也用这个连接finalshell]**，如图：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230714202344043.png" alt="image-20230714202344043" style="zoom:33%;" />

最后修改静态IP：

```
[root@hadoop100 ~]# vim /etc/sysconfig/network-scripts/ifcfg-ens33
```

加上IP和网关：

```
IPADDR=192.168.10.102           #改为本机网段hadoop2是102  3是103
GATEWAY=192.168.10.2
DNS1=192.168.10.2
```

重启即可:

```
[root@hadoop100 ~]# reboot
```





#### 3.集群发布脚本xsync和免密登陆配置

scp安全拷贝的语法：

```
scp -r $pdir/$fname $user@$host:$pdir/$fname

命令 递归 要拷贝的文件路径/名称 目的地用户@主机:目的地路径/名称
```



把脚本安排在：/home/lchen/bin下的xsync文件中            【bin目录和文件自己建】

脚本：

```
#!/bin/bash
#1. 判断参数个数
if [ $# -lt 1 ]
then
 echo Not Enough Arguement!
 exit;
fi
#2. 遍历集群所有机器
for host in hadoop102 hadoop103 hadoop104
do
 echo ==================== $host ====================
 #3. 遍历所有目录，挨个发送
 for file in $@
 do
 #4. 判断文件是否存在
 if [ -e $file ]
 then
 #5. 获取父目录
 pdir=$(cd -P $(dirname $file); pwd)
 #6. 获取当前文件的名称
 fname=$(basename $file)
 ssh $host "mkdir -p $pdir"
 rsync -av $pdir/$fname $host:$pdir
 else
 echo $file does not exists!
 fi
 done
done
```

添加命令，赋予脚本权限：

```
[atguigu@hadoop102 bin]$ chmod +x xsync          
```

```
[atguigu@hadoop102 bin]$ sudo cp xsync /bin/   复制脚本到bin中方便全局调用
```

让环境变量生效：（这一步三台机器都要进行，当然要在xync传输到其他2台机器之后）

```
[atguigu@hadoop103 bin]$ source /etc/profile
[atguigu@hadoop104 opt]$ source /etc/profile
```



利用传输语法给另外两台机器发送脚本：

```
xsync xsync
```

当然要输入密码。之后那两台机器记得source哟



接下来我们设置免密登陆，这样就可以不输入密码了：

- 3台集群同时调用远程连接命令

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230714212426639.png" alt="image-20230714212426639" style="zoom:25%;" />

以此类推，连接其他两个机器



- 3台机器全都cd 到~/.ssh/（root用户也是这样操作）

调用命令生成密钥

```
ssh-keygen -t rsa
```



- 把密钥发给其他机器（一起发）【你可以理解为发间谍到其他机器里去】

```
[atguigu@hadoop102 .ssh]$ ssh-copy-id hadoop102
[atguigu@hadoop102 .ssh]$ ssh-copy-id hadoop103
[atguigu@hadoop102 .ssh]$ ssh-copy-id hadoop104
```





### （2）JDK部署

查看本机是否安装java

```
rpm -qa | grep -i java 
```

一行都没输出——没有java



在software目录下安装软件：

```
 cd /opt/software/
```

把JDK拖拽到该目录下，

然后解压到/opt/module  

```
tar -zxvf 文件名  -C /opt/module                
```

**这一步我出了问题，解决方法——把finallshell的连接用户切换到root用户**

把JDK发给其他两台机器

```
 xsync jdk1.8.0_212/
```

**注意：要注意你这个文件是谁的？如果是root用户的，那么只能以root用户的身份进行传输，否则不得行。**

当然:你如果是其他用户用sudo也是可以的：例如：

```
sudo    /home/lchen/xsync       /etc/profile.d/my_env.sh
权限升级 +  脚本位置  +发送位置
```



**设置javaHome**

这里我用：

```
[atguigu@hadoop102 ~]$ sudo vim /etc/profile.d/my_env.sh
```

添加以下内容：

```
#JAVA_HOME
export JAVA_HOME=/opt/module/jdk1.8.0_212
export PATH=$PATH:$JAVA_HOME/bin
```

**发给其他机器：**

```
sudo    /home/lchen/xsync       /etc/profile.d/my_env.sh
```



source 一下/etc/profile 文件，让新的环境变量 PATH 生效**（3台都要）**

```
[atguigu@hadoop102 ~]$ source /etc/profile
```

#####  测试 JDK 是否安装成功

```
[atguigu@hadoop102 ~]$ java -version
```

![image-20230716212055170](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230716212055170.png)

成功！





#### 环境变量说明：

Linux的环境变量可以再多个文件中配置，如：

/etc/profile.d/*.sh          ~/bashrc                   ~/.bash_profile等

下面说明这几个文件的关系与区别：

linxu命令行（bash）的命令模式分为：

- 登陆的——login shell                              （常规命令都是login模式）   
- 非登陆的——non-login shell                      （ssh远程连接就是non-login）

**注意两种模式的命令所调到的环境变量是不一样的！**

这就导致有些命令无法用于远程连接如——ll

**两种模式对应的环境变量设置如下：**

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230717214331657.png" alt="image-20230717214331657" style="zoom:33%;" />

如图：如果我想让环境变量同时作用于两种模式，就在~/.bashrc/etc/bashrc/etc/profile.d下创建*.sh文件。





#### 配置脚本查看节点进程

```
 cd /bin              进入全局bin文件夹
 vim xcall.sh          创建脚本文件
```

脚本文件内容：

```
#! /bin/bash
 
for i in hadoop102 hadoop103 hadoop104
do
    echo --------- $i ----------
    ssh $i "$*"
done
```

赋予脚本权限：

```
chmod +x xcall.sh
```



然后我们就可以通过xcall命令访问三台机器的进程：（**必须在bin目录里才能使用该脚本命令**）

```
 xcall.sh jps
```

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230718202131834.png" alt="image-20230718202131834" style="zoom:33%;" />









### （3）大数据软件安装

#### 1.安装ZooKeeper

- cd到 /opt/software，将压缩包放进去

然后解压到modile文件夹中：

```
 tar -zxvf apache-zookeeper-3.7.1-bin.tar.gz -C /opt/module/
```

cd到modile文件夹，给软件文件夹改个名字，以后好区分：

```
mv apache-zookeeper-3.7.1-bin/ zookeeper
```



- 进入zookeeper文件夹

创建一个存数据的文件夹（名字自定义）：

```
 mkdir zkData
```

在这个文件夹下创建myid文件（**注意这个文件名字固定，就是myid。不能改**）

```
vim myid
```

里面给zookeeeper文件编号：



进入配置文件（conf文件夹下的）：

把zookeeper/conf下的 zoo_sample.cfg文件更名为zoo.cfg：

```
 mv zoo_sample.cfg  zoo.cfg
```

然后进入这个文件修改以下配置：

（1）修改文件存储路径为自定义文件夹

![image-20230718203631049](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230718203631049.png)

（2）在末尾添加三个机器

![image-20230718204140320](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230718204140320.png)



- 把zookeeper分发给其他机器，**并且把对应的myid文件里的编号分别改成3和4**

```
xsync zookeeper/
```

然后修改编号（以hadoop3为例）：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230718204549648.png" alt="image-20230718204549648" style="zoom:50%;" />





- 启动zookeeper

启动命令：（这个需要每台机器都输入一遍）

```
bin/zkServer.sh start
```

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230718205058700.png" alt="image-20230718205058700" style="zoom:33%;" />

可见三台机器都已经启动Zookeeper



- 当然为了启动更方便，我们自然要安排上群起群停的脚本：

直接在 bin/目录下（是系统的bin目录）创建脚本文件：zk.sh

```
#!/bin/bash
case $1 in
"start"){
for i in hadoop102 hadoop103 hadoop104
do
echo ---------- zookeeper $i 启动 ------------
ssh  $i  "/opt/module/zookeeper/bin/zkServer.sh start"
done
};;
"stop"){
for i in hadoop102 hadoop103 hadoop104
do
echo ---------- zookeeper $i 停止 ------------
ssh  $i  "/opt/module/zookeeper/bin/zkServer.sh stop"
done
};;
"status"){
for i in hadoop102 hadoop103 hadoop104
do
echo ---------- zookeeper $i 状态 ------------
ssh  $i  "/opt/module/zookeeper/bin/zkServer.sh status"
done
};;
esac
```

添加脚本权限：

```
chmod +x zk.sh
```

那么现在我们就可以通过脚本文件启动/停止zookeeper了：

```
zk.sh stop
zk.sh start
```

成功：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230718210846088.png" alt="image-20230718210846088" style="zoom:33%;" />



#### 2.安装Hadoop

```
首先我们依然还是先把安装包上传：
cd /opt/software
```

解压到mode目录下：

```
 tar -zxvf hadoop-3.3.4.tar.gz  -C /opt/module/
```

最后再chmod一下免得后面麻烦：

```
chmod -R 777 ./hadoop
```







- 添加Hadoop到环境变量

```
vim /etc/profile.d/my_env.sh 
```

添加：

```
#Hadoop_HOME
export HADOOP_HOME=/opt/module/hadoop
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin
```

分法环境变量给其他机器：

```
xsync /etc/profile.d/my_env.sh
或者：
/home/lchen/bin/xsync    /etc/profile.d/my_env.sh
```

加载环境变量（source一下）：

最好机器全都source一遍

```
source /etc/profile.d/my_env.sh 
```





- 修改文件名为hadoop并修改配置


```
 mv hadoop-3.3.4/  hadoop
 cd  $HADOOP_HOME/etc/hadoop
```

编辑hadoop文件夹里的core-site.xml

文件内容如下：(把atguigu改成lchen)

```
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
<!-- 把多个NameNode的地址组装成一个集群mycluster -->
  <property>
    <name>fs.defaultFS</name>
    <value>hdfs://mycluster</value>
  </property>

  <!-- 指定hadoop运行时产生文件的存储目录 -->
  <property>
    <name>hadoop.tmp.dir</name>
    <value>/opt/module/hadoop/data</value>
  </property>
<!-- 配置NN故障转移的 ZK集群-->
<property>
	<name>ha.zookeeper.quorum</name>
	<value>hadoop102:2181,hadoop103:2181,hadoop104:2181</value>
</property>

<!-- 配置HDFS网页登录使用的静态用户为atguigu -->
    <property>
        <name>hadoop.http.staticuser.user</name>
        <value>lchen</value>
</property>

<!-- 配置该atguigu(superUser)允许通过代理访问的主机节点 -->
    <property>
        <name>hadoop.proxyuser.lchen.hosts</name>
        <value>*</value>
</property>
<!-- 配置该atguigu(superUser)允许通过代理用户所属组 -->
    <property>
        <name>hadoop.proxyuser.lchen.groups</name>
        <value>*</value>
</property>
<!-- 配置该atguigu(superUser)允许通过代理的用户-->
    <property>
        <name>hadoop.proxyuser.lchen.users</name>
        <value>*</value>
</property>

    
</configuration>
```

编译：hdfs-site.xml

```
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>

<!-- NameNode数据存储目录 -->
  <property>
    <name>dfs.namenode.name.dir</name>
    <value>file://${hadoop.tmp.dir}/name</value>
  </property>

  <!-- DataNode数据存储目录 -->
  <property>
    <name>dfs.datanode.data.dir</name>
    <value>file://${hadoop.tmp.dir}/data</value>
  </property>

  <!-- JournalNode数据存储目录 -->
  <property>
    <name>dfs.journalnode.edits.dir</name>
    <value>${hadoop.tmp.dir}/jn</value>
  </property>

  <!-- 完全分布式集群名称 -->
  <property>
    <name>dfs.nameservices</name>
    <value>mycluster</value>
  </property>

  <!-- 集群中NameNode节点都有哪些 -->
  <property>
    <name>dfs.ha.namenodes.mycluster</name>
    <value>nn1,nn2</value>
  </property>

  <!-- NameNode的RPC通信地址 -->
  <property>
    <name>dfs.namenode.rpc-address.mycluster.nn1</name>
    <value>hadoop102:8020</value>
  </property>
  <property>
    <name>dfs.namenode.rpc-address.mycluster.nn2</name>
    <value>hadoop103:8020</value>
  </property>

  <!-- NameNode的http通信地址 -->
  <property>
    <name>dfs.namenode.http-address.mycluster.nn1</name>
    <value>hadoop102:9870</value>
  </property>
  <property>
    <name>dfs.namenode.http-address.mycluster.nn2</name>
    <value>hadoop103:9870</value>
  </property>

  <!-- 指定NameNode元数据在JournalNode上的存放位置 -->
  <property>
    <name>dfs.namenode.shared.edits.dir</name>
<value>qjournal://hadoop102:8485;hadoop103:8485;hadoop104:8485/mycluster</value>
  </property>

  <!-- 访问代理类：client用于确定哪个NameNode为Active -->
  <property>
    <name>dfs.client.failover.proxy.provider.mycluster</name>
    <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
  </property>

  <!-- 配置隔离机制，即同一时刻只能有一台服务器对外响应 -->
  <property>
    <name>dfs.ha.fencing.methods</name>
    <value>sshfence</value>
  </property>

  <!-- 使用隔离机制时需要ssh秘钥登录-->
  <property>
    <name>dfs.ha.fencing.ssh.private-key-files</name>
    <value>/home/lchen/.ssh/id_rsa</value>
  </property>
<!-- 启用nn故障自动转移 -->
<property>
	 <name>dfs.ha.automatic-failover.enabled</name>
	 <value>true</value>
</property>    
    <!-- 测试环境指定HDFS副本的数量1 -->
    <property>
        <name>dfs.replication</name>
        <value>3</value>
    </property>


</configuration>
```

配置yarn-site.xml:

```
<property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>

    <!-- 启用resourcemanager ha -->
    <property>
        <name>yarn.resourcemanager.ha.enabled</name>
        <value>true</value>
    </property>
 
    <!-- 声明两台resourcemanager的地址 -->
    <property>
        <name>yarn.resourcemanager.cluster-id</name>
        <value>cluster-yarn1</value>
    </property>

    <!--指定resourcemanager的逻辑列表-->
    <property>
        <name>yarn.resourcemanager.ha.rm-ids</name>
        <value>rm1,rm2</value>
    </property>
<!-- ========== rm1的配置 ========== -->
    <!-- 指定rm1的主机名 -->
    <property>
        <name>yarn.resourcemanager.hostname.rm1</name>
        <value>hadoop102</value>
    </property>

    <!-- 指定rm1的web端地址 -->
    <property>
        <name>yarn.resourcemanager.webapp.address.rm1</name>
        <value>hadoop102:8088</value>
    </property>

    <!-- 指定rm1的内部通信地址 -->
    <property>
        <name>yarn.resourcemanager.address.rm1</name>
        <value>hadoop102:8032</value>
    </property>

    <!-- 指定AM向rm1申请资源的地址 -->
    <property>
        <name>yarn.resourcemanager.scheduler.address.rm1</name>  
        <value>hadoop102:8030</value>
    </property>

    <!-- 指定供NM连接的地址 -->  
    <property>
    <name>yarn.resourcemanager.resource-tracker.address.rm1</name>
        <value>hadoop102:8031</value>
    </property>

<!-- ========== rm2的配置 ========== -->
    <!-- 指定rm2的主机名 -->
    <property>
        <name>yarn.resourcemanager.hostname.rm2</name>
        <value>hadoop103</value>
    </property>
    <property>
        <name>yarn.resourcemanager.webapp.address.rm2</name>
        <value>hadoop103:8088</value>
    </property>
    <property>
        <name>yarn.resourcemanager.address.rm2</name>
        <value>hadoop103:8032</value>
    </property>
    <property>
        <name>yarn.resourcemanager.scheduler.address.rm2</name>
        <value>hadoop103:8030</value>
    </property>

    <property>
<name>yarn.resourcemanager.resource-tracker.address.rm2</name>
        <value>hadoop103:8031</value>
    </property>


    <!-- 指定zookeeper集群的地址 --> 
    <property>
        <name>yarn.resourcemanager.zk-address</name>
        <value>hadoop102:2181,hadoop103:2181,hadoop104:2181</value>
    </property>

    <!-- 启用RM自动故障转移 --> 
    <property>
        <name>yarn.resourcemanager.recovery.enabled</name>
        <value>true</value>
    </property>
 
    <!-- 指定resourcemanager的状态信息存储在zookeeper集群 --> 
    <property>
        <name>yarn.resourcemanager.store.class</name>     <value>org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore</value>
</property>

    <!-- 环境变量的继承 -->
    <property>
        <name>yarn.nodemanager.env-whitelist</name>
        <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME</value>
    </property>
    
    <!--yarn单个容器允许分配的最大最小内存 -->
    <property>
        <name>yarn.scheduler.minimum-allocation-mb</name>
        <value>512</value>
    </property>
    <property>
        <name>yarn.scheduler.maximum-allocation-mb</name>
        <value>4096</value>
    </property>
    
    <!-- yarn容器允许管理的物理内存大小 -->
    <property>
        <name>yarn.nodemanager.resource.memory-mb</name>
        <value>4096</value>
    </property>
    
    <!-- 关闭yarn对物理内存和虚拟内存的限制检查 -->
    <property>
        <name>yarn.nodemanager.pmem-check-enabled</name>
        <value>true</value>
    </property>
    <property>
        <name>yarn.nodemanager.vmem-check-enabled</name>
        <value>false</value>
    </property>

<!-- 开启日志聚集功能 -->
<property>
    <name>yarn.log-aggregation-enable</name>
    <value>true</value>
</property>

<!-- 设置日志聚集服务器地址 -->
<property>  
    <name>yarn.log.server.url</name>  
    <value>http://hadoop102:19888/jobhistory/logs</value>
</property>

<!-- 设置日志保留时间为7天 -->
<property>
    <name>yarn.log-aggregation.retain-seconds</name>
    <value>604800</value>
</property>

```

配置mapred-site.xml：

```
<!-- 指定MapReduce程序运行在Yarn上 -->
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
<!-- 历史服务器端地址 -->
<property>
    <name>mapreduce.jobhistory.address</name>
    <value>hadoop102:10020</value>
</property>

<!-- 历史服务器web端地址 -->
<property>
    <name>mapreduce.jobhistory.webapp.address</name>
    <value>hadoop102:19888</value>
</property>


```

配置worker:

```
hadoop102
hadoop103
hadoop104
```

**配置mapred-site.xml**

```
<!-- 历史服务器端地址 -->
<property>
    <name>mapreduce.jobhistory.address</name>
    <value>hadoop102:10020</value>
</property>

<!-- 历史服务器web端地址 -->
<property>
    <name>mapreduce.jobhistory.webapp.address</name>
    <value>hadoop102:19888</value>
</property>

```

最好分发Hadoop给其他机器：

```
 xsync hadoop/
```





#### 3.启动Hadoop-HA

- 启动journalnode服务，3台机器都要启动(root)

```
hdfs --daemon start journalnode
```

第一次启动会显示一个文件不存在，没关系

若出现权限不够：

```
sudo chmod -R  777  /opt/module/hadoop
```



- hadoop102执行格式化并启动

```
hdfs namenode -format
hdfs --daemon start namenode
```



- 在hadoop103同步nn1的元数据信息

```
hdfs namenode -bootstrapStandby
```



- hadoop102初始化协议

```
hdfs zkfc -formatZK
```

注意你的zookeep要先启动

- 启动zkfc      所有节点即可

```
hdfs --daemon start zkfc
```



- 在所有节点上，启动datanode

```
hdfs --daemon start datanode
```



- 查看进程

```
xcall.sh jps
```

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230722173159342.png" alt="image-20230722173159342" style="zoom:25%;" />

若出现jps后无法查看Hadoop进程，但是Hadoop却能正常运行（http://hadoop102:9870/能正常访问）：

这是因为`hsperfdata_hadoop` 和 `hsperfdata_root` 的权限不一致，

修改 `hsperfdata_hadoop` 的权限：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230724210347725.png" alt="image-20230724210347725" style="zoom:33%;" />

```
hmod 755 /temp/hsperfdata_*
```





- 启动命令

以后我们就可以直接通过脚本启动了：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230722173259597.png" alt="image-20230722173259597" style="zoom:33%;" />



- 停止相关服务

```
stop-dfs.sh
```

用lchen用户，root用户不得行。因为我们配置文件里配的是lchen





#### 4.Hadoop群起脚本

```
cd /home/lchen/bin

vim hdp.sh
```

编写内容：

```
#!/bin/bash
if [ $# -lt 1 ]
then
    echo "No Args Input..."
    exit ;
fi
case $1 in
"start")
        echo " =================== 启动 hadoop集群 ==================="

        echo " --------------- 启动 hdfs 和 yarn ---------------"
        ssh hadoop102 "/opt/module/hadoop/sbin/start-all.sh"
        echo " --------------- 启动 historyserver ---------------"
        ssh hadoop102 "/opt/module/hadoop/bin/mapred --daemon start historyserver"
;;
"stop")
        echo " =================== 关闭 hadoop集群 ==================="

        echo " --------------- 关闭 historyserver ---------------"
        ssh hadoop102 "/opt/module/hadoop/bin/mapred --daemon stop historyserver"
        echo " --------------- 关闭 hdfs 和 yarn ---------------"
        ssh hadoop102 "/opt/module/hadoop/sbin/stop-all.sh"
;;
*)
    echo "Input Args Error..."
;;
esac

```

添加脚本权限：

```
chmod 777 hdp.sh
```

复制到root的脚本目录下，方便root用户使用：

```
sudo cp xsync /bin/   复制脚本到bin中方便全局调用
```

启动集群：（以lchen的身份）

```
./hdp.sh start
```







#### 问题归纳（⭐）

- 权限问题  chmod -R命令解决
- 报错——可能是zookeeper没有启动/用户需要使用lchen
- JPS没东西，但是hadoop102:9870可以正常访问（修改 `hsperfdata_hadoop` 的权限：）

**若报错：**

```
ERROR: Unable to write in /opt/module/hadoop-3.1.3/logs. Aborting.
```

解决方法：(三台机器都需要)

```
sudo chmod -R 777 /opt/module/hadoop/logs
```

**若报错：**

```
ERROR: Cannot write namenode pid /tmp/hadoop-longda-namenode.pid
```

解决方法（三台机器）：

```
sudo chmod 777 -R /tmp 
```

**若出现：**

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230723161648343.png" alt="image-20230723161648343" style="zoom:25%;" />

解决方法：

```
[lchen@hadoop102 tmp]$ cd /tmp
[lchen@hadoop102 tmp]$ rm -rf hsperfdata_*
```

**权限问题解决语法：**

```
“sudo chown -R 用户名:用户名 赋予的文件路径
```

参考博客：https://blog.csdn.net/qq_44920169/article/details/116330119

**气死>~<，一直有权限问题，我直接就把lchen权限改为root：**（⭐）

修改 /etc/sudoers 文件:

```
%wheel  ALL=(ALL)       ALL下面一行：
注释掉：
lchen ALL=(ALL) NOPASSWD:ALL

找到并添加：
## Allow root to run any commands anywhere 
root    ALL=(ALL)       ALL
lchen ALL=(ALL)         ALL
```





#### 终于成功了！（重装了三遍呐😭）

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230724211458100.png" alt="image-20230724211458100" style="zoom:33%;" />

查看进程：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230724211431643.png" alt="image-20230724211431643" style="zoom:33%;" />

#### 2.1小问题

- 搞了以后出了一个小问题，我的Hadoop在102和103上都有namenode故我只能在103上查看HDFS，不过好像没什么问题。

  参考博客：https://blog.csdn.net/weixin_51967583/article/details/121435007

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230729174433560.png" alt="image-20230729174433560" style="zoom:25%;" />

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230729174610012.png" alt="image-20230729174610012" style="zoom:25%;" />

我们查看hadoop102的namenode状态：

![image-20230729174359156](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230729174359156.png)

如果我们想借由hadoop102查看：

```
hdfs haadmin -transitionToActive --forcemanual nn1
```

重启Hadoop即可完成：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230803155900514.png" alt="image-20230803155900514" style="zoom:25%;" />

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230822204611610.png" alt="image-20230822204611610" style="zoom:25%;" />





#### 2.2HDFS多目录配置以及机器的集合（了解）

查看磁盘使用情况：

```
df -h
```

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230724212230138.png" alt="image-20230724212230138" style="zoom:33%;" />

如果你是多磁盘可以考虑多目录配置：

hdfs-site.xml文件中配置多目录：

```
<property>
<name>dfs.datanode.data.dir</name>
<value>file:///dfs/data1,file:///hd2/dfs/data2,file:///hd3/dfs/data3,file:///hd4/dfs/data4</value>
</property>
```

**注意：每台服务器挂载的磁盘不一样，所以每个节点的多目录配置可以不一致。单独配置即可。**

我就不配了=_=没啥用。



- 节点数据均衡（可以不用管，默认已经开启了数据均衡）

```
start-balancer.sh -threshold 10
表示各个节点的磁盘空间利用率不超过10%，默认情况下就是这么多
```

关闭平衡：

```
stop-balancer.sh
```



- 磁盘间的数据平衡

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230725095813808.png" alt="image-20230725095813808" style="zoom: 33%;" />











#### 3.安装Kafka

压缩包放到/opt/software里，然后解压：

```
tar -zxvf kafka_2.12-3.3.1.tgz -C /opt/module/
```

然后我们进入module文件夹改名为kafka就行



- 修改配置文件

```
cd config/
 vim server.properties
```

改这些地方：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230725105908477.png" alt="image-20230725105908477" style="zoom:50%;" />

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230725110032470.png" alt="image-20230725110032470" style="zoom:33%;" />

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230725110216201.png" alt="image-20230725110216201" style="zoom:33%;" />



```
分发软件包：
xsync kafka/
```





- 改一下另外两机器的配置文件的id号

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230725111818214.png" alt="image-20230725111818214" style="zoom:33%;" />

104id改成3，下面改成hadoop104即可





- 配置环境变量

```
 sudo vim /etc/profile.d/my_env.sh 
```

添加环境：

```
#KAFKA_HOME

export KAFKA_HOME=/opt/module/kafka

export PATH=$PATH:$KAFKA_HOME/bin
```

然后分发文件，最后加载环境变量（三台都要）

```
 sudo /home/lchen/bin/xsync  /etc/profile.d/my_env.sh 
source /etc/profile
```



- 启动集群（它俩利于zookeeper，要先启动zookeeper）

依次在hadoop102、hadoop103、hadoop104节点上启动Kafka。

```
sudo bin/kafka-server-start.sh -daemon config/server.properties
```



**若jps发现没有Kafka，查看日志文件报错：**

nohup: 无法运行命令"java": 没有那个文件或目录

解决方法：赋予权限

```
sudo chmod 777 -R kafka/
```

再启动就行了：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230725121519881.png" alt="image-20230725121519881" style="zoom:33%;" />

配置群起群停的脚本：

在lchen的bin目录：kf.sh

内容：

```
#! /bin/bash

case $1 in
"start"){
    for i in hadoop102 hadoop103 hadoop104
    do
        echo " --------启动 $i Kafka-------"
        ssh $i "/opt/module/kafka/bin/kafka-server-start.sh -daemon /opt/module/kafka/config/server.properties"
    done
};;
"stop"){
    for i in hadoop102 hadoop103 hadoop104
    do
        echo " --------停止 $i Kafka-------"
        ssh $i "/opt/module/kafka/bin/kafka-server-stop.sh "
    done
};;
esac

```

**添加执行权限**

```
chmod 777 kf.sh
```

**启动/停止命令：**

```
kf.sh start
kf.sh stop
```



**成功！**

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230725122126246.png" alt="image-20230725122126246" style="zoom:25%;" />

注意：你必须先关kafka再关zookeeper，否则Kafka关不掉，只能手动杀死进程



##### Kafka的简介

​	一个典型的 Kafka 包含若干Producer、若干 Broker、若干 Consumer 以及一个 Zookeeper 集群。Zookeeper 是 Kafka 用来负责集群元数据管理、控制器选举等操作的。Producer 是负责将消息发送到 Broker 的，Broker 负责将消息持久化到磁盘，而 Consumer 是负责从Broker 订阅并消费消息。

相关概念：

1. Broker—— Kafka 服务器，它**接受生产者发送的消息并存入磁盘**
2. Cluster——若**干个 Broker 组成一个 集群（Cluster）**，其中集群内某个 Broker 会成为集群控制器，它负责管理集群，包括分配分区到 Broker、监控 Broker 故障等。
3. 主题——**消息以 主题（Topic）来分类，每一个主题都对应一个「消息队列」**，这有点儿类似于数据库中的表。
4. 分区——就是相当于通道



**相关命令：**

- 查看当前kafka有多少主题

```
bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --list
```

- 创建主题

```bash
bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --create --partitions 1  --replication-factor 3 --topic 名字
```

其中：

1. --partitions 1 表示分区个数为1
2. replication-factor 3 表示副本个数为3
3. --topic 名字  给主题起名字

注意：你可以不创建主题直接使用，必然直接调用生产者它可以自己创建一个主题

- 查看主题详情

```
 bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --describe --topic 主题名字
```

- 修改分区数（只能加不能减）

```
bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --alter --topic first --partitions 3
```

- 删除主题

```
 bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --delete --topic first
```

如图：（主题car的创建和删除）

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230725212312372.png" alt="image-20230725212312372" style="zoom:33%;" />



- 生产者和消费者命令（⭐）

启动生产者：（hadoo102）：

```
bin/kafka-console-producer.sh --bootstrap-server hadoop102:9092 --topic 主题名字
```

如果该主题没有提前创建，会自动创建并警告

启动消费者接收数据（103）：

```
kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --topic 主题名字
```

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230725214049575.png" alt="image-20230725214049575" style="zoom:33%;" />

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230725214102199.png" alt="image-20230725214102199" style="zoom:33%;" />



#### 4.安装Fluem

一样的解压操作，把文件名改一下即可。

修改一下它的配置文件设置——修改conf目录下的log4j2.xml：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230725215513353.png" alt="image-20230725215513353" style="zoom:33%;" />

设置启动使用Flume时打印日志文件内容，方便我们找错：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230725215722851.png" alt="image-20230725215722851" style="zoom:33%;" />

分发到各个机器：

```
xsync flume/
```



*注：（了解）修改/opt/module/flume/conf/flume-env.sh文件可以配置Flume内存，如果是数据量很大，内存需求很大，可能要配置





#### 5.mysql安装

由于mysql工具包多，我们需要单独创建一个mysql文件夹，然后解压，重命名操作一样。

```
 sudo mkdir mysql
```



- 卸载mysql依赖

虽然机器上没有装MySQL，但是这一步不可少

```
sudo yum remove mysql-libs
```



- 重新安装依赖

```
sudo yum install libaio
 sudo yum -y install autoconf
```



- 切换到root用户，查看安装脚本（**注意是查看，它已经有了**）

**/opt/software/mysql/****目录下install_mysql.sh**:

```
#!/bin/bash
set -x
[ "$(whoami)" = "root" ] || exit 1
[ "$(ls *.rpm | wc -l)" = "7" ] || exit 1
test -f mysql-community-client-8.0.31-1.el7.x86_64.rpm && \
test -f mysql-community-client-plugins-8.0.31-1.el7.x86_64.rpm && \
test -f mysql-community-common-8.0.31-1.el7.x86_64.rpm && \
test -f mysql-community-icu-data-files-8.0.31-1.el7.x86_64.rpm && \
test -f mysql-community-libs-8.0.31-1.el7.x86_64.rpm && \
test -f mysql-community-libs-compat-8.0.31-1.el7.x86_64.rpm && \
test -f mysql-community-server-8.0.31-1.el7.x86_64.rpm || exit 1

# 卸载MySQL
systemctl stop mysql mysqld 2>/dev/null
rpm -qa | grep -i 'mysql\|mariadb' | xargs -n1 rpm -e --nodeps 2>/dev/null
rm -rf /var/lib/mysql /var/log/mysqld.log /usr/lib64/mysql /etc/my.cnf /usr/my.cnf

set -e
# 安装并启动MySQL
yum install -y *.rpm >/dev/null 2>&1
systemctl start mysqld

#更改密码级别并重启MySQL
sed -i '/\[mysqld\]/avalidate_password.length=4\nvalidate_password.policy=0' /etc/my.cnf
systemctl restart mysqld

# 更改MySQL配置
tpass=$(cat /var/log/mysqld.log | grep "temporary password" | awk '{print $NF}')
cat << EOF | mysql -uroot -p"${tpass}" --connect-expired-password >/dev/null 2>&1
set password='000000';
update mysql.user set host='%' where user='root';
alter user 'root'@'%' identified with mysql_native_password by '000000';
flush privileges;
EOF

```

- 执行脚本

```
 sh install_mysql.sh
```

最后切换回lchen用户即可



- 进入mysql命令：

```
mysql -uroot -p000000
```

-p000000表示密码是6个0

如图：进入成功

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230726154601370.png" alt="image-20230726154601370" style="zoom:33%;" />



退出命令：

```
quit            退出mysql
exit            退出root用户
```







## 四.项目开始（数仓环境搭建）

### 1.数据模拟和采集

数据：

- 业务数据
- 用户日志——新能源汽车的运行日志

#### （1）数据模拟

在/opt/module中新建car-data目录，将car-data-1.0.1-jar-with-dependencies.jar.jar上传到改目录中（脚本在学习资料moke文件夹中）

**脚本使用参数命令：**

```
java -jar car-data-1.0.1-jar-with-dependencies.jar
usage: 参数错误，可用参数列表如下
-c,--count <arg>      模拟天数，-1表示无限模拟，默认为无限模拟
    -cars <arg>       模拟车辆数目，1-10000，默认为100
    -d,--date <arg>       模拟开始日期, 格式为’yyyy-MM-dd’, 必须指定
    -n,--username <arg>   维度数据的JDBC用户名, 必须指定
    -o,--output <arg>     模拟数据输出目录，默认为./data
    -p,--password <arg>   维度数据的JDBC密码, 必须指定
    -u,--url <arg>        维度数据的JDBC URL, 必须指定

```

当然你也可以通过命令去了解这个jar包的使用方法：

```
java -jar car-data-1.0.1-jar-with-dependencies.jar
```



- 当然我们先要到mysql数据库中创建数据库

  这里我们使用Navicat可视化连接虚拟机数据库工具（网上找破解版就行）

**若连接报错：**

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230726173035329.png" alt="image-20230726173035329" style="zoom:33%;" />

解决方案：

在mysql数据行输入以下命令：

```
alter user 'root'@'%' identified with mysql_native_password by '000000';

flush privileges;
```

连接成功：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230726173328395.png" alt="image-20230726173328395" style="zoom:33%;" />



- 创建一个名为"car_data"的数据库，并指定该数据库使用UTF-8字符集（utf8mb4）和一般的UTF-8排序规则（utf8mb4_general_ci）。

```
mysql -uroot -p000000 -e"create database car_data charset utf8mb4 collate utf8mb4_general_ci"
```

如图：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230726173556727.png" alt="image-20230726173556727" style="zoom:33%;" />

执行下列命令，生成数据：（右键复制标签，不要退出mysql）

```
java -jar \
car-data-1.0.1-jar-with-dependencies.jar \
-c 1 \
-d 2023-07-01 \
-n root \
-p 000000 \
-u jdbc:mysql://hadoop102:3306/car_data

```

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230726174004050.png" alt="image-20230726174004050" style="zoom:33%;" />

**报错：**

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230726174637021.png" alt="image-20230726174637021" style="zoom:33%;" />

注意要在cardata目录下，并赋予该文件夹权限，否则它造不出来目录：

```
sudo chmod 777 -R  文件夹
```

**成功：**

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230726174749299.png" alt="image-20230726174749299" style="zoom:33%;" />

同时我们查看可视化数据库：（生成了两张表）

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230726175050376.png" alt="image-20230726175050376" style="zoom:33%;" />



- 创造脚本生成数据

以后我们想创建数据都可以通过那个jar包创建，但是这样比较麻烦，我们想创建一个脚本，以数据时间为参数，方便我们生成数据

就在lchen/bin目录下创建lg.sh：

```
#!/bin/bash
if [ "$#" -ne 1 ]
then
echo "没有传入日期参数！"
exit 1
fi

java -jar \
/opt/module/car-data/car-data-1.0.1-jar-with-dependencies.jar \
-c 1 \
    -o /opt/module/car-data/data \
    -d "$1" \
    -n root \
    -p 000000 \
    -u jdbc:mysql://hadoop102:3306/car_data

```

然后赋能给这个脚本文件：

```
sudo chmod 777 lg.sh
```

将脚本发给bin目录方便全局可用

```
sudo cp lg.sh /bin/

sudo chmod 777 lg.sh
```

我们将数据库的表删除，再把data这个文件夹删除（这样数据就完全去除了）。然后用脚本重新造一下数据：

```
cd /opt/module/car-data/

lg.sh 2023-07-26
```

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230726180919240.png" alt="image-20230726180919240" style="zoom:33%;" />

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230726180956197.png" alt="image-20230726180956197" style="zoom:33%;" />

#### （2）日志数据采集

数据路径：

数据——>Flume——>Kafka——>Flume——>HDFS

**Kafka的目的是为了增强扩展性。**

为了以防万一，我配给flume文件夹权限：

```
sudo chmod 777 flume/
```



- 配置Flume工作配置文件

1.创建工作文件夹

```
[lchen@hadoop102 flume]$ mkdir job
```

2.创建连接配置文件

```
[lchen@hadoop102 job]$ touch file_to_kafka.conf
```

利用finalshell对配置文件进行修改：

```
#定义组件
a1.sources = r1
a1.channels = c1

#配置source(taildir source)
a1.sources.r1.type = TAILDIR           
a1.sources.r1.filegroups = f1
a1.sources.r1.filegroups.f1 = /opt/module/car-data/data/data.*
a1.sources.r1.positionFile = /opt/module/flume/car/taildir_position.json

#配置channel(kafka channel)
a1.channels.c1.type = org.apache.flume.channel.kafka.KafkaChannel
a1.channels.c1.kafka.bootstrap.servers = hadoop102:9092,hadoop103:9092,hadoop104:9092
a1.channels.c1.kafka.topic = car_data
a1.channels.c1.parseAsFlumeEvent = false
#组装 
a1.sources.r1.channels = c1

```

1. a1.sources.r1.type = TAILDIR ——sources.组件类型
2. a1.sources.r1.filegroups——表示文件组
3. a1.sources.r1.positionFile——断点续长文件（用于动态读取）
4. a1.channels.c1.type——channel组件类型
5. a1.channels.c1.kafka.bootstrap.servers——Kafka端口
6. a1.channels.c1.kafka.topic ——写入Kafka哪个主题
7. a1.channels.c1.parseAsFlumeEvent ——设置数据传输方式是不是event对象（填false因为kafka是以字符串来读取数据的而不是event对象）



**测试flume是否采集数据并且连接Kafka：**

先到lchen/bin目录下启动kafka(利用脚本):

```
[lchen@hadoop102 bin]$ ./kf.sh start
```

去flume目录下启动Fluem，根据配置文件采集数据：

```
bin/flume-ng agent -n a1 -c conf/ -f job/file_to_kafka.conf
```

复制hadoop102标签，启动一个Kafka的消费者，查看是否已经接收数据：

```
bin/kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --topic car_data --from-beginning

```



flume正在读取数据：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230727212045278.png" alt="image-20230727212045278" style="zoom:25%;" />

Kafka消费者接收到数据：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230727212513573.png" alt="image-20230727212513573" style="zoom:25%;" />

看到数据源源不断的打印即成功！



好，我们又来设置一个flume的启动脚本，**因为我们用命令开启它始终会在前台挂起不能动，很不方便**

一样的在lchen/bin下

fl.sh:

```
#!/bin/bash
case $1 in
"start"){
echo " --------启动hadoop102采集flume-------"
ssh hadoop102 "nohup /opt/module/flume/bin/flume-ng agent -n a1 -c /opt/module/flume/conf/ -f /opt/module/flume/job/file_to_kafka.conf >/dev/null 2>&1 &"
};; 
"stop"){
echo " --------停止hadoop102采集flume-------"
ssh hadoop102 "ps -ef | grep file_to_kafka | grep -v grep |awk  '{print \$2}' | xargs -n1 kill -9 "
};;
esac

```

给权限：

```
sudo chmod 777 fl.sh
```



- 编写消费者flume

也就是第二个flume，我们通过它把数据上传给HDFS。我们在**hadoop104里配置消费者flume**

cd到flume目录下：（最好先给flume文件夹chmod一下）

```
[lchen@hadoop104 module]$ cd flume/
[lchen@hadoop104 flume]$ mkdir job
[lchen@hadoop104 flume]$ cd job/
[lchen@hadoop104 job]$ touch kafka_to_hdfs.conf
```

同理，我们 添加配置文件kafka_to_hdfs.conf：（用三个组件）

```
#定义组件
a1.sources=r1
a1.channels=c1
a1.sinks=k1

#配置source1
a1.sources.r1.type = org.apache.flume.source.kafka.KafkaSource
a1.sources.r1.kafka.bootstrap.servers = hadoop102:9092,hadoop103:9092,hadoop104:9092
a1.sources.r1.kafka.consumer.auto.offset.reset = earliest
a1.sources.r1.kafka.consumer.group.id = flume
a1.sources.r1.kafka.topics=car_data


#配置channel
a1.channels.c1.type = file
a1.channels.c1.checkpointDir = /opt/module/flume/checkpoint/behavior1
a1.channels.c1.dataDirs = /opt/module/flume/data/behavior1
a1.channels.c1.maxFileSize = 2146435071
a1.channels.c1.capacity = 1000000
a1.channels.c1.keep-alive = 6

#配置sink
a1.sinks.k1.type = hdfs
a1.sinks.k1.hdfs.path = /origin_data/car_data_full/%Y-%m-%d
a1.sinks.k1.hdfs.filePrefix = log
a1.sinks.k1.hdfs.round = false


a1.sinks.k1.hdfs.rollInterval = 30
a1.sinks.k1.hdfs.rollSize = 134217728
a1.sinks.k1.hdfs.rollCount = 0

#控制输出文件类型
a1.sinks.k1.hdfs.fileType = CompressedStream
a1.sinks.k1.hdfs.codeC = gzip
#组装 
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1

```

1. a1.channels.c1.type——缓存位置（默认是内存，我们改成磁盘也就是file）
2. a1.channels.c1.dataDirs——缓存存储路径（注意：一个服务器可能启动多个flume故该属性最好编号，因为其他配置文件也要设置）
3. a1.channels.c1.checkpointDir——保证不同管道不同数据
4. a1.channels.c1.keep-alive——数据保存时间
5. a1.channels.c1.capacity——数据容量（条）
6. a1.channels.c1.maxFileSize ——文件最大大小
7. a1.sinks.k1.hdfs.fileType——是否压缩
8. a1.sinks.k1.hdfs.codeC——压缩格式



- 添加Flume拦截器

为啥要添加拦截器？

为了避免数据飘逸的问题——由于没能及时将数据输送到HDFS导致时间出现落成，从而导致时间紊乱：

例如：

我1号23：59生产数据并且被flume1采集，但是等数据传输到Flume2时已经到了2好0：01分。虽然文件（bodey）还是显示是1号数据，但是Flume头信息(header)却显示是2号



首先我们打开IDEA，创建maven项目并且添加依赖：

```
    <dependencies>
        <dependency>
            <groupId>org.apache.flume</groupId>
            <artifactId>flume-ng-core</artifactId>
            <version>1.10.1</version>
        </dependency>
    </dependencies>

```

然后我们就可以开始设计拦截器了：

```
public class Timestampinterceptor implements Interceptor {
    @Override
    public void initialize() {//初始化

    }

    @Override
    public Event intercept(Event event) {
       try {//try语法用于数据过滤
           //将body的数据时间戳写入头信息中，提供给HDFS使用
           //将数据写入正确的分区中   解决数据飘逸问题
           Map<String, String> headers = event.getHeaders();//获取头信息
           String log = new String(event.getBody(), StandardCharsets.UTF_8);//获取body信息
           JsonParser jsonParser = new JsonParser();  //google的工具，用于解析JSON
           JsonObject asJsonObject = jsonParser.parse(log).getAsJsonObject();//将数据解析成json对象
           String timestamp = asJsonObject.get("timestamp").getAsString();//获取时间戳数据并转换成string类型
           //写入header中
           headers.put("timestamp",timestamp);

           return event;
       }catch (Exception e){
           e.printStackTrace();//打印异常
           return null;
       }
    }

    @Override
    public List<Event> intercept(List<Event> events) {
        Iterator<Event> iterator = events.iterator();
        while (iterator.hasNext()) {
            Event next = iterator.next();
            if (intercept(next)==null) {
                iterator.remove();
            }
        }
    return events;
    }

    @Override
    public void close() {//关闭

    }

//编写静态内部类，这样才能和flume对接
    public static class Builder implements Interceptor.Builder{

    @Override
    public Interceptor build() {
        return new Timestampinterceptor();
    }

    @Override
    public void configure(Context context) {

    }
}


}
```

这里演示了一下数据过滤的做法（其实没有脏数据就可以不用过滤）

回到flume配置文件，添加配置：

```
a1.sources.r1.interceptors = i1
a1.sources.r1.interceptors.i1.type = flume.interceptor.Timestampinterceptor$Builder
```

1. a1.sources.r1.interceptors——声明拦截器
2. a1.sources.r1.interceptors.i1.type——拦截器类（参数是类的路径，右键点击复制引用即可）



- 打包拦截器到虚拟机


<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230729164247845.png" alt="image-20230729164247845" style="zoom: 25%;" />

完成后我们可以看到打包完成后的代码：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230729164404849.png" alt="image-20230729164404849" style="zoom:25%;" />

上传到hadoop104的flume/lib下





- 开始尝试上传

启动Hadoop

```
./hdp.sh start
```

启动flume

```
bin/flume-ng agent -c conf/ -f job/kafka_to_hdfs.conf  -n a1
```

这里我们遇见了一个报错（版本问题）

核心关键报错是Unsupported major.minor version 52.0。经过查询，了解是jdk版本不支持的原因，[version](https://so.csdn.net/so/search?q=version&spm=1001.2101.3001.7020) 52.0即jdk1.8的意思。因为flume解析器是jdk1.8编译的，而CDH集群是使用jdk1.7，所以导致无法调用。

**但是我发现我的虚拟机Java版本本来就是1.8的，仔细一看原来是我本地的JDK是1.9版本，于是我把 IDEA的maven版本改变为1.8即可，方法就是修改pom文件：**

```
<properties>
        <maven.compiler.source>1.8</maven.compiler.source>
        <maven.compiler.target>1.8</maven.compiler.target>
    </properties>
```



好，由于我配置Hadoop的时候一不小心在102和103上全都配了namenode导致102上访问不了HDFS了。但是好像并不影响我的传输，我们可以看到：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230729173002135.png" alt="image-20230729173002135" style="zoom:33%;" />

成功！



- 封装flume2号的启动脚本：

```
[lchen@hadoop102 bin]$ sudo vim f2.sh
```

添加如下内容：

```
#!/bin/bash
case $1 in
"start")
echo " --------启动hadoop104日志数据flume-------"
ssh hadoop104 "nohup /opt/module/flume/bin/flume-ng agent -n a1 -c /opt/module/flume/conf -f /opt/module/flume/job/kafka_to_hdfs.conf >/dev/null 2>&1 &"
;;
"stop")
echo " --------停止hadoop104日志数据flume-------"
ssh hadoop104 "ps -ef | grep kafka_to_hdfs | grep -v grep |awk '{print \$2}' | xargs -n1 kill"
;;
esac

```

添加权限：（以后就可以这样启动flume2了）

```
[lchen@hadoop102 bin]$ sudo chmod 777 f2.sh 
```





### 2.维度数据同步

- 维度数据的同步


1.全量同步——将每天的数据全部放入数据仓库：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230729195815774.png" alt="image-20230729195815774" style="zoom:25%;" />

逻辑简单但是其缺点很明显，有大量重复的数据。所以适用于小型数据



2.增量同步——每天只将有数据变化/新增的数据同步到数据仓库

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230729200120046.png" alt="image-20230729200120046" style="zoom:25%;" />

效率很高但是逻辑复杂需要对数据变化进行整理



#### (1)DataX的使用

原理：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230729203635499.png" alt="image-20230729203635499" style="zoom:25%;" />

安装一样，拖拽，解压，改名即可。

```
sudo chmod 777 目录   //给权限
```

- 运行演示案例，查看是否安装完成

先cd到datax

```
[lchen@hadoop102 datax]$ python bin/datax.py job/job.json 
```

这样输出即运行成功：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230730201749757.png" alt="image-20230730201749757" style="zoom:25%;" />



- 使用datax

```
 python bin/datax.py   + job目录下的配置文件
```

至于配置文件怎么书写，我们可以通过命令查看配置文件的模板：

```
python bin/datax.py -r mysqlreader -w hdfswriter
```

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230730202224535.png" alt="image-20230730202224535" style="zoom:25%;" />

当然这个了解一下就行了，不推荐照着他的模板来。我们还是看官网好些：https://github.com/alibaba/DataX/blob/master/README.md



例如：

- 配置一个从Mysql数据库同步抽取数据到本地的作业:

```
{
    "job": {
        "setting": {
            "speed": {
                 "channel": 3
            },
            "errorLimit": {
                "record": 0,
                "percentage": 0.02
            }
        },
        "content": [
            {
                "reader": {
                    "name": "mysqlreader",
                    "parameter": {
                        "username": "root",
                        "password": "root",
                        "column": [
                            "id",
                            "name"
                        ],
                        "splitPk": "db_id",
                        "connection": [
                            {
                                "table": [
                                    "table"
                                ],
                                "jdbcUrl": [
     "jdbc:mysql://127.0.0.1:3306/database"
                                ]
                            }
                        ]
                    }
                },
               "writer": {
                    "name": "streamwriter",
                    "parameter": {
                        "print":true
                    }
                }
            }
        ]
    }
}

```

- 写入HDFS：（只复制writer部分即可）


```
"writer": {
                    "name": "hdfswriter",
                    "parameter": {
                        "defaultFS": "hdfs://xxx:port",
                        "fileType": "orc",
                        "path": "/user/hive/warehouse/writerorc.db/orcfull",
                        "fileName": "xxxx",
                        "column": [
                            {
                                "name": "col1",
                                "type": "TINYINT"
                            },
                            {
                                "name": "col2",
                                "type": "SMALLINT"
                            },
                            {
                                "name": "col3",
                                "type": "INT"
                            },
                            {
                                "name": "col4",
                                "type": "BIGINT"
                            },
                            {
                                "name": "col5",
                                "type": "FLOAT"
                            },
                            {
                                "name": "col6",
                                "type": "DOUBLE"
                            },
                            {
                                "name": "col7",
                                "type": "STRING"
                            },
                            {
                                "name": "col8",
                                "type": "VARCHAR"
                            },
                            {
                                "name": "col9",
                                "type": "CHAR"
                            },
                            {
                                "name": "col10",
                                "type": "BOOLEAN"
                            },
                            {
                                "name": "col11",
                                "type": "date"
                            },
                            {
                                "name": "col12",
                                "type": "TIMESTAMP"
                            }
                        ],
                        "writeMode": "append",
                        "fieldDelimiter": "\t",
                        "compress":"NONE"
                    }
                }
```

合并模板：（把第一部分writer部分用第二部分代替）

```
{
    "job": {
        "setting": {
            "speed": {
                 "channel": 3
            },
            "errorLimit": {
                "record": 0,
                "percentage": 0.02
            }
        },
        "content": [
            {
                "reader": {
                    "name": "mysqlreader",
                    "parameter": {
                        "username": "root",
                        "password": "000000",
                        "column": [
                            "id",
							"type_id",
                            "type",
                            "sale_type",
                            "trademark",
                            "company",
                            "seating_capacity",
                            "power_type",
                            "charge_type",
                            "category",
                            "weight_kg",
                            "warranty"
                        ],
                        "connection": [
                            {
                                "table": [
                                    "car_info"
                                ],
                                "jdbcUrl": [
     "jdbc:mysql://hadoop102/car_data"
                                ]
                            }
                        ]
                    }
                },
               "writer": {
                    "name": "hdfswriter",
                    "parameter": {
                    "hadoopConfig": {
                            "dfs.nameservices": "mycluster",
                            "dfs.namenode.rpc-address.mycluster.nn2": "hadoop103:8020",
                            "dfs.namenode.rpc-address.mycluster.nn1": "hadoop102:8020",
                            "dfs.client.failover.proxy.provider.mycluster": 			  "org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider", 
                            "dfs.ha.namenodes.mycluster": "nn1,nn2"
                        },

                        "defaultFS": "hdfs://mycluster",
                        "fileType": "text",
                        "path": "/test",
                        "fileName": "car_info",
                        "column": [
                           {
                                "name": "id",
                                "type": "string"
                            },
                            {
                                "name": "type_id",
                                "type": "string"
                            },
                            {
                                "name": "type",
                                "type": "string"
                            },
                            {
                                "name": "sale_type",
                                "type": "string"
                            },
                            {
                                "name": "trademark",
                                "type": "string"
                            },
                            {
                                "name": "company",
                                "type": "string"
                            },
                            {
                                "name": "seating_capacity",
                                "type": "bigint"
                            },
                            {
                                "name": "power_type",
                                "type": "string"
                            },
                            {
                                "name": "charge_type",
                                "type": "string"
                            },
                            {
                                "name": "category",
                                "type": "string"
                            },
                            {
                                "name": "weight_kg",
                                "type": "bigint"
                            },
                            {
                                "name": "warranty",
                                "type": "string"
                            }
                        ],
                        "writeMode": "append",
                        "fieldDelimiter": "\t",
                        "compress":"gzip"
                    }
                }
            }
        ]
    }
}

```

**相关参数改写：**

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230731204539520.png" alt="image-20230731204539520" style="zoom: 33%;" />

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230731204734391.png" alt="image-20230731204734391" style="zoom:33%;" />



#### 案例（配置文件就是上面那个）

之前我们不是在mysql中创建了模拟数据的两张表吗，现在我们通过Datax同步到HDFS中.

***小技巧：我们可以右键表名——转储SQL文件——仅结构——把该文件保存在某一位置，打开就能复制所有的属性名了，不然一个一个写很麻烦。**

1.创建配置文件，把上面的复制进去

```
[lchen@hadoop102 root]$ cd /opt/module/datax/
[lchen@hadoop102 datax]$ cd job/
[lchen@hadoop102 job]$ vim test.json
```

2.运行datax（zookeeper和Hadoop要全部启动）

```
[lchen@hadoop102 datax]$ hadoop fs -mkdir /test
[lchen@hadoop102 datax]$ python bin/datax.py  job/test.json 
```

**注意datax无法在hdfs目录下创建文件夹，故传输数据前我们自己要创建**

3.传输成功：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230731211244681.png" alt="image-20230731211244681" style="zoom:25%;" />

我们去HDFS（http://hadoop103:9870/explorer.html#/）里确认一下：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230731211358405.png" alt="image-20230731211358405" style="zoom:33%;" />

可视化页面由于是压缩包gz格式无法直接读取，我们可以通过linux命令查看其中的数据：

```
[lchen@hadoop102 datax]$ hadoop fs -text /test/*
```

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230731211645822.png" alt="image-20230731211645822" style="zoom:25%;" />





#### （2）Datax的参数使用

- QuerySQLMode（QuerySQL模式）

即**使用SQL语言选择数据上传**，之前配置文件里的称之为table模式指定属性上传。如图例子所示：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230731212459007.png" alt="image-20230731212459007" style="zoom:25%;" />

- datax传参（⭐）

这个传参是非常有用的。

例子：

我每天都有数据从mysql传入/同步到Hadoop，不可能传入同一个文件夹。故**我的路径应该提供一个变量**，每天的文件根据变量传入对应文件夹。

datax配置文件中我们的写入路径这么写：

```
"path": "/base_province/${dt}",
```

这个时候我们就可以通过命令传参，将数据传入对应文件夹：

```
hadoop fs -mkdir /test/参数                //先创建传入的文件夹
python bin/datax.py -p"-Ddt=参数" job/test.json   //将数据传入参数文件夹中
```

如图：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230802152530036.png" alt="image-20230802152530036" style="zoom:25%;" />

完成：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230802152710595.png" alt="image-20230802152710595" style="zoom:25%;" />



- 同步HDFS数据到MySQL中

在项目尾部展示



#### （3）Datax维度表同步（放到HDFS里）

我们把配置文件名字改一下——car_info.json（里面的参数变哈）

每次写命令挺麻烦的，我们编一个脚本：（lchen/bin目录下）

```
#!/bin/bash
if [ "$#" -ne 1 ]
then
echo "参数错误！"
exit 1
fi
targetdir="/origin_data/car_info_full/$1"
# 确保HDFS目录存在且为空
hadoop fs -rm -r "${targetdir}"
hadoop fs -mkdir -p "${targetdir}"

# 执行DataX任务
/opt/module/datax/bin/datax.py /opt/module/datax/job/car_info.json -p"-Ddt=${targetdir}"
```

添加权限：

```
chmod 777  脚本
```

以后我们就可以通过脚本把数据从mysql传入HDFS了

```
mysql_to_hdfs.sh + 参数
```

第一次跑会报错，没关系。只要HDFS里有就行：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230804213932207.png" alt="image-20230804213932207" style="zoom:33%;" />

**注意点：你那个参数两个文件必须一致。不然搞不起：**

![image-20230804215728377](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230804215728377.png)







### 3.数据仓库

#### （1）相关概念

- **数据库规范化：**

是使用一系列范式设计数据库，其目的是为了减少数据冗余，需要遵从不同范式。

关系型数据库一个6种范式，如1NF,2NF,3NF等。范式级别越高数据冗余越低。

***注意：范式之间是递进的关系，要满足后面的范式你需要先满足前面的范式。**



- **三范式：**

1. 第一范式——**属性不可切割**

例如：

| 商品    | 商家id |
| ------- | ------ |
| 5台电脑 | xxxx   |

其中商品可以切割为5台+电脑（包含两个信息）。故该表格不符合第一范式

下面这张就符合了：

| 商品 | 数量 | 商家id |
| ---- | ---- | ------ |
| 电脑 | 5    | xxxxxx |



2.第二范式——**不存在部分函数依赖**

什么是函数依赖？

指的是**非主键的任意一列与主键之间的关系**

**完全函数依赖——任意主键和在一起能推出非主键（例如通过学号+课程推出分数）**

**部分函数依赖——不需要所有主键就能推出非主键（例如通过学号推出姓名）**

举个栗子：

| 学号（主键） | 姓名 | 科目（主键） | 分数 |
| ------------ | ---- | ------------ | ---- |
| 110          | 龙   | 数学         | 150  |
| 111          | 蛇   | 数学         | 150  |
| 112          | 虎   | 物理         | 150  |

上面的表就不符合第二范式，因为存在部分函数依赖，可通过学号——推出姓名。

**想要实现第二范式只需要把这个表拆碎就行了（即把符合完全函数依赖的列拆出来，把主键写上）**，如下图就符合第二范式：

| 学号（主键） | 科目（主键） | 分数 |
| ------------ | ------------ | ---- |
| 110          | 数学         | 150  |
| 111          | 数学         | 150  |
| 112          | 物理         | 150  |





3.第三范式——**不能存在传递函数依赖**

**什么是传递函数依赖？——主键和列名是多对一的关系，然后这个列名和另一列是一对一的关系**

例如：

学号（主键）——可以推出学院。但是学院不能推出学号。

学院——可以推出系主任，但是系主任也不能推出学号。

如图：

| 学号（主键） | 名字 | 学院   | 系主任 |
| ------------ | ---- | ------ | ------ |
| 10201        | 星   | 计算机 | 王     |
| 10202        | 夜   | 经管   | 陈     |

一个学院对应多个学号，对应一个系主任。

**怎么变化成满足第三范式——把传递函数依赖的列拆开：**

| 学号  | 姓名 | 学院   |
| ----- | ---- | ------ |
| 10201 | 星   | 计算机 |
| 10202 | 夜   | 经管   |

和

| 学院   | 系主任 |
| ------ | ------ |
| 计算机 | 王     |
| 经管   | 陈     |





#### （2）数据仓库建模理论：

- ER模型——实体关系模型（就是上面的范式）

将复杂的数据抽象为两个概念——实体和关系。实体表示一个对象，例如学生，班级。关系是指两个实体之间的关系，例如学生与班级之间的从属关系



- 维度模型


将复杂的业务通过事实和维度两个概念呈现。

说人话——参与计算的列放入事实表，不参与计算的列放入维度表

*注：业务过程可以概括为一个个不可拆分的行为事件，例如下单，付款，加购等都是业务过程。





#### （3）维度模型事实表和维度表的介绍

事实表：

建模的核心，特点是细长，列比较少（**因为表述信息都在维度表，它只需要存储id**），但是行比较多，行的增速比较快。

事实表可以分为三类：

- 事务事实表（最常用）

设计流程：

1. 选择业务过程（例如下单，付款等）
2. 声明粒度（就是精确的表示每行数据表示的啥，尽可能选择最细粒度）
3. 确认维度
4. 确认事实

- 周期快照事实表
- 累计快照事实表





维度表：

是业务过程所处的环境。

设计步骤：

1. 确定维度表
2. 确定主维表和相关维表
3. 确定维度属性





#### （4）搭建数据仓库运行环境

- 安装部署Hive

一样的，**拖拽，解压，改名，赋权**

然后我们配置环境变量：

```
sudo vim /etc/profile.d/my_env.sh
```

添加以下信息：

```
#HIVE_HOME
export HIVE_HOME=/opt/module/hive
export PATH=$PATH:$HIVE_HOME/bin
```

把它分发一下：

```
sudo /home/lchen/bin/xsync /etc/profile.d/my_env.sh 
```

然后source一下：

```
[lchen@hadoop102 module]$ source /etc/profile.d/my_env.sh 
```

解决jar包冲突：

```
[lchen@hadoop102 hive]$ mv lib/log4j-slf4j-impl-2.17.1.jar lib/log4j-slf4j-impl-2.17.1.jar.bak
```



- 把hive元数据配置到mysql

添加mysql取第

```
[lchen@hadoop102 hive]$ sudo cp /opt/software/mysql/mysql-connector-j-8.0.31.jar lib/
```

修改配置文件：

```
[lchen@hadoop102 hive]$ vim conf/hive-site.xml
```

文件里写入如下内容：

```
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
    <!--配置Hive保存元数据信息所需的 MySQL URL地址-->
    <property>
        <name>javax.jdo.option.ConnectionURL</name>
        <value>jdbc:mysql://hadoop102:3306/metastore?useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF-8&amp;allowPublicKeyRetrieval=true</value>
    </property>

    <!--配置Hive连接MySQL的驱动全类名-->
    <property>
        <name>javax.jdo.option.ConnectionDriverName</name>
        <value>com.mysql.cj.jdbc.Driver</value>
    </property>

    <!--配置Hive连接MySQL的用户名 -->
    <property>
        <name>javax.jdo.option.ConnectionUserName</name>
        <value>root</value>
    </property>

    <!--配置Hive连接MySQL的密码 -->
    <property>
        <name>javax.jdo.option.ConnectionPassword</name>
        <value>000000</value>
    </property>

    <property>
        <name>hive.metastore.warehouse.dir</name>
        <value>/user/hive/warehouse</value>
    </property>

    <property>
        <name>hive.metastore.schema.verification</name>
        <value>false</value>
    </property>

    <property>
        <name>hive.metastore.event.db.notification.api.auth</name>
        <value>false</value>
    </property>
</configuration>

```



- 启动hive

复制标签，登陆mysql：

```
 mysql -uroot -p000000
 新建hive数据库：
 mysql> create database metastore;
```

初始化hive元数据：（命令行执行）

```
schematool -initSchema -dbType mysql -verbose
```

成功：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230802173313694.png" alt="image-20230802173313694" style="zoom:33%;" />

我们可以到mysql可视化工具中查看：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230802173410889.png" alt="image-20230802173410889" style="zoom:25%;" />

修改元数据字符集，避免乱码现象：

首先来到刚刚创建的数据库（metastore）：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230802173907724.png" alt="image-20230802173907724" style="zoom:25%;" />

```
字段注释：
mysql> alter table metastore.COLUMNS_V2 modify column COMMENT varchar(256) character set utf8mb4;

表注释：
mysql> alter table metastore.TABLE_PARAMS modify column PARAM_VALUE mediumtext character set utf8mb4;

推出mysql：
mysql> quit;
```



- 启动hive客户端

```
[lchen@hadoop102 hive]$ hive
```

执行命令查看数据库，若能展示则没有问题：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230802175854947.png" alt="image-20230802175854947" style="zoom:33%;" />





- 替换Hive引擎

Hive的默认引擎是MR，速度很慢，我们替换成spark

那么就有两种用法：

1. Hive on spark （语法还是用HQL，不过底层走的是sparkRDD计算）
2. spark on hive （语法走的是spark sql语法）

本项目用的是Hive on Spark





上传解压spark。

然后修改其中的spark环境配置文件：

```
[lchen@hadoop102 spark]$ sudo vim conf/spark-env.sh.template 
```

在文件末尾添加这句话：

```
export SPARK_DIST_CLASSPATH=$(hadoop classpath)
```

修改文件名，去掉后缀使其生效：

```
[lchen@hadoop102 conf]$ sudo mv spark-env.sh.template spark-env.sh
```



配置spark环境变量：

```
[lchen@hadoop102 conf]$ sudo vim /etc/profile.d/my_env.sh 
```

添加如下内容：

```
# SPARK_HOME
export SPARK_HOME=/opt/module/spark
export PATH=$PATH:$SPARK_HOME/bin

```

source使其生效：

```
[lchen@hadoop102 conf]$ source /etc/profile.d/my_env.sh 
```



在hive里面创建spark配置文件：

```
vim /opt/module/hive/conf/spark-defaults.conf
```

添加如下内容：

```
spark.master                yarn

spark.eventLog.enabled          true

spark.eventLog.dir            hdfs://mycluster/spark-history

spark.executor.memory          1g

spark.driver.memory           1g
```

在HDFS中创建日志文件：

```
 hadoop fs -mkdir /spark-history
```



向HDFS上传spark纯净版的jar包：

说明：

1. 使用spark纯净版的jar包，不包含Hadoop和hive的相关依赖，能避免依赖冲突
2. hive任务由spark执行，资源由yarn调度，该任务也可能分配在集群任意节点，所以spark依赖要需要上传到Hadoop集群路径，这样任何节点都能到。

```
hadoop fs -mkdir /spark-jars
```

上传spark相关jar包：

```
[lchen@hadoop102 conf]$ cd /opt/module/spark/jars/
[lchen@hadoop102 jars]$ hadoop fs -put ./* /spark-jars
```



现在就可以替换spark引擎了：

```
[lchen@hadoop102 jars]$ cd /opt/module/hive/
[lchen@hadoop102 hive]$ sudo vim conf/hive-site.xml 
```

在末尾位置添加以下内容：

```
<!--Spark依赖位置（注意：端口号8020必须和namenode的端口号一致）-->
<property>
    <name>spark.yarn.jars</name>
    <value>hdfs://mycluster/spark-jars/*</value>
</property>
  
<!--Hive执行引擎-->
<property>
    <name>hive.execution.engine</name>
    <value>spark</value>
</property>

```

测试一下替换是否成功：

进入本地客户端：

```
hive
```

创建一张测试表并且插入数据：

```
create table student(id int, name string);
insert into table student values(1,'abc');           这就是一个spark任务
```

出现下面内容即成功：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230803153644887.png" alt="image-20230803153644887" style="zoom:25%;" />

我们可以在yarn上监控到该任务：http://hadoop102:8088/cluster

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230803154034148.png" alt="image-20230803154034148" style="zoom:25%;" />





- yarn的环境配置

引言：

我们同时打开两个hive客户端，执行上面的命令，我们发现其中一个spark任务一直处于“提交”状态，无法完成。

这是因为：

容量调度器对每个资源队列中同时运行的Application Master占用的资源进行了限制，该限制通过yarn.scheduler.capacity.maximum-am-resource-percent参数实现，其默认值是0.1，表示每个资源队列上Application Master最多可使用的资源为该队列总资源的10%，目的是防止大部分资源都被Application Master占用，而导致Map/Reduce Task无法执行。

我们回到yarn上来看：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230803154751134.png" alt="image-20230803154751134" style="zoom:25%;" />



解决方案：

修改/opt/module/hadoop/etc/hadoop/capacity-scheduler.xml文件：

```
[lchen@hadoop102 hive]$ cd /opt/module/hadoop/etc/hadoop/
[lchen@hadoop102 hadoop]$ sudo vim capacity-scheduler.xml 
```

修改参数：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230803155238359.png" alt="image-20230803155238359" style="zoom:25%;" />

分发一下这个配置文件：

```
[lchen@hadoop102 hadoop]$ xsync capacity-scheduler.xml 
```

**然后重启hadoop**





- 连接datagrip


首先在hive文件夹启动hiveserver2：

```
[lchen@hadoop102 hive]$ hiveserver2
```

在datagrip里连接Hadoop102机器

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230804085640726.png" alt="image-20230804085640726" style="zoom:33%;" />

连接完成之后，可能虚拟机这边会报以下异常，不用管他。这是最新版本没有所有功能导致的。

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230804085841681.png" alt="image-20230804085841681" style="zoom:25%;" />

还有一个问题需要解决，hiveserver2后台频繁出现OOM（内存溢出的异常）。这是因为hive默认内存只有256M，不够。所以我们需要改一下：

```
[lchen@hadoop102 root]$ cd /opt/module/hive/
[lchen@hadoop102 hive]$ cd conf/
[lchen@hadoop102 conf]$ sudo mv hive-env.sh.template  hive-env.sh     修改后缀激活该文件
[lchen@hadoop102 conf]$ sudo vim hive-env.sh 
```

把设置内容的注释解了，如图得到：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230804090341973.png" alt="image-20230804090341973" style="zoom: 25%;" />

重启hiveserver2

```
hiveserver2
```



还有一个地方我们需要提前修改：

Hive表的序列化和反序列化器用来解析JSON文件，我们需要**在hive-site.xml中添加配置：**

在最后一行添加如下配置即可：

```
<property>
<name>metastore.storage.schema.reader.impl</name>
<value>org.apache.hadoop.hive.metastore.SerDeStorageSchemaReader</value>
</property>

```







## 五.搭建数仓

整体架构：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230804203518790.png" alt="image-20230804203518790" style="zoom:25%;" />

回顾数据模拟部分：也许你需要回顾一下数据怎么生成的还有怎么采集的。

数据流向：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230804221424284.png" alt="image-20230804221424284" style="zoom:33%;" />









### （1）生成2023-07-27号的数据

注意，你要把zookeep,hadoop,Flume(2台)，Kafka全启动。其中zookeeper需要最先启动，Kafka启动在flume之前。

```
[lchen@hadoop102 bin]$ ./kf.sh start
 --------启动 hadoop102 Kafka-------
 --------启动 hadoop103 Kafka-------
 --------启动 hadoop104 Kafka-------
[lchen@hadoop102 bin]$ ./f1.sh start
bash: ./f1.sh: 没有那个文件或目录
[lchen@hadoop102 bin]$ ./fl.sh start
 --------启动hadoop102采集flume-------
[lchen@hadoop102 bin]$ ./f2.sh start

```



- 创建2023-07-27的汽车日志数据

```
[lchen@hadoop102 bin]$ lg.sh 2023-07-27

```

只有你前面Kafka和flume都启动了，数据会自动上传至HDFS：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230804212716616.png" alt="image-20230804212716616" style="zoom:33%;" />

我们点击进入这个文件夹，当没有tmp临时文件时则说明数据已经上传完毕：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230804213114481.png" alt="image-20230804213114481" style="zoom:33%;" />



把维度数据也放到HDFS里/origin_data（全量同步）：

```
[lchen@hadoop102 bin]$ ./mysql_to_hdfs.sh 2023-07-27
```

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230804220548842.png" alt="image-20230804220548842" style="zoom:25%;" />

这里咱思考一个问题：（⭐）

为什么flume通常采集日志数据而不是维度数据？

​	数据格式和结构：维度数据通常是结构化的数据，例如数据库中的表格数据或者数据仓库中的维度表。这种数据已经经过处理和整理，具有明确的数据模式和字段定义。相比之下，日志数据通常是非结构化或半结构化的文本数据，其格式和结构可能会有所不同，需要进行解析和提取。Flume提供了丰富的日志数据处理工具和插件，能够帮助用户解析和处理各种格式的日志数据。





### （2）数仓分层介绍

*注：原始数据是OLTP系统数据，符合三范式。但是我们想要利于分析的系统OLAP故要进行转换，数据也会**从三范式ER模型转换成维度模型**

#### 1.分层规划：（最少五层，可多不可少）

1. 数据应用层（ADS）

   存放各项统计指标结果。

2. 汇总数据层（DWS）

   基于上层指标需求，以分析主题的对象作为建模驱动，构建公共统计粒度汇总表

3. 明细数据层（DWD）——维度建模

   **基于维度建模理论构建，存放事实表。**保存业务过程最小粒度操作记录

4. 公共维度层（DIM）——维度建模

   **基于维度建模理论构建，存放维度表**，保存一致的维度信息。

5. 原始数据层（ODS）

**存放没有经过处理的原始数据**，不会对数据进行处理。是数据仓库的数据准备区



- 相关概念：

OLTP——擅长CRUD（增删改查）的数据概论存储系统。主要数据操作是随机读写，主要采用满足 3NF 的实体关系型存储数据

OLAP——面向的主要数据操作是批量读写，不关注事务处理的一致性，主要关注数据的整合，以及在一次性的复杂数据查询和处理中的性能（数据分析）

ER模型——从全企业的高度设计一个 3NF 模型，用实体关系（ER）模型描述企业业务，在范式理论上符合 3NF。

维度模型——从分析决策的需求出发构建模型，为分析需求服务，重点关注用户如何更快速的完成需求分析，具有较好的大规模复杂查询的响应性能

数据粒度——数据粒度其实就是指数据仓库的数据单位中保存数据的细化或综合程度的级别。



维度模型分为两个表：

1. 事实表——存储最细的业务事件
2. 维度表——记录业务事件的环境



#### 2.维度模型（单独介绍）

这里我们以星型模型为例

我们在进行维度建模的时候会建一张事实表，这个事实表就是星型模型的中心，然后会有一堆维度表，这些维度表就是向外发散的星星：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230805104155741.png" alt="image-20230805104155741" style="zoom:25%;" />

**图中的订单表（ICstockbill）就是一个事实表**，你可以理解他就是在现实中发生的一次操作型事件，我们每完成一个订单，就会在订单中增加一条记录。我们可以回过头再看一下事实表的特征，**在事实表里没有存放实际的内容，他是一堆主键的集合**，这些ID分别能对应到维度表中的一条记录。

**每个维度表都包含单一的主键列。**图中的customer（客户表）、goods(商品表)、d_time(时间表)这些都属于维度表，这些表都有一个唯一的主键，然后在表中存放了详细的数据信息。





### （3）原始数据层（ODS层）搭建

关于把文本数据转换成hive表的内容可以参考 “hive学习笔记”

------

一句话概括任务——**把数据变成hive表格**

ODS层设计要点：

1. ODS层要保存所有的历史数据，故器压缩个数比较高，此处选择gzip

2. 命名规范：

   ```
   ods_表名_标识（inc/full）全量表/增量表
   ```

   如日志一般都是增量表，汽车信息一般是全量表



- 如何把JSON数据（不一定是JSON文件）转变陈hive表格

方式一：

所用JSON数据：（需要放到hdfs）

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230805205227607.png" alt="image-20230805205227607" style="zoom:25%;" />

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230806100507026.png" alt="image-20230806100507026" style="zoom:25%;" />

**注意JSON解析的是一个文件夹里的所有数据，故要在单独的文件夹下创建数据文件。**

启动hive：

```
[lchen@hadoop102 root]$ cd /opt/module/hive/
[lchen@hadoop102 hive]$ hiveserver2
```

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230806101700339.png" alt="image-20230806101700339" style="zoom:33%;" />

输出结果：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230806101712866.png" alt="image-20230806101712866" style="zoom:33%;" />



方法二：serde

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230806104238692.png" alt="image-20230806104238692" style="zoom:33%;" />



#### 1.生成车辆日志表（增量表）

- 首先创建表，并存入HDFS

```
create external table ods_car_data_inc
(
    `vin`                                         string comment '汽车唯一ID',
    `car_status`                                  int comment '车辆状态',
    `charge_status`                               int comment '充电状态',
    `execution_mode`                              int comment '运行模式',
    `velocity`                                    int comment '车速',
    `mileage`                                     int comment '里程',
    `voltage`                                     int comment '总电压',
    `electric_current`                            int comment '总电流',
    `soc`                                         int comment 'SOC',
    `dc_status`                                   int comment 'DC-DC状态',
    `gear`                                        int comment '挡位',
    `insulation_resistance`                       int comment '绝缘电阻',
    `motor_count`                                 int comment '驱动电机个数',
    `motor_list`                                  array<struct<`id` :int, `status` :int, `rev` :int, `torque` :int,
                                                               `controller_temperature` :int, `temperature` :int,
                                                               `voltage`
                                                               :int, `electric_current` :int>> comment '驱动电机列表',
    `fuel_cell_voltage`                           int comment '燃料电池电压',
    `fuel_cell_current`                           int comment '燃料电池电流',
    `fuel_cell_consume_rate`                      int comment '燃料消耗率',
    `fuel_cell_temperature_probe_count`           int comment '燃料电池温度探针总数',
    `fuel_cell_temperature`                       int comment '燃料电池温度值',
    `fuel_cell_max_temperature`                   int comment '氢系统中最高温度',
    `fuel_cell_max_temperature_probe_id`          int comment '氢系统中最高温度探针号',
    `fuel_cell_max_hydrogen_consistency`          int comment '氢气最高浓度',
    `fuel_cell_max_hydrogen_consistency_probe_id` int comment '氢气最高浓度传感器代号',
    `fuel_cell_max_hydrogen_pressure`             int comment '氢气最高压力',
    `fuel_cell_max_hydrogen_pressure_probe_id`    int comment '氢气最高压力传感器代号',
    `fuel_cell_dc_status`                         int comment '高压DC-DC状态',
    `engine_status`                               int comment '发动机状态',
    `crankshaft_speed`                            int comment '曲轴转速',
    `fuel_consume_rate`                           int comment '燃料消耗率',
    `max_voltage_battery_pack_id`                 int comment '最高电压电池子系统号',
    `max_voltage_battery_id`                      int comment '最高电压电池单体代号',
    `max_voltage`                                 int comment '电池单体电压最高值',
    `min_temperature_subsystem_id`                int comment '最低电压电池子系统号',
    `min_voltage_battery_id`                      int comment '最低电压电池单体代号',
    `min_voltage`                                 int comment '电池单体电压最低值',
    `max_temperature_subsystem_id`                int comment '最高温度子系统号',
    `max_temperature_probe_id`                    int comment '最高温度探针号',
    `max_temperature`                             int comment '最高温度值',
    `min_voltage_battery_pack_id`                 int comment '最低温度子系统号',
    `min_temperature_probe_id`                    int comment '最低温度探针号',
    `min_temperature`                             int comment '最低温度值',
    `alarm_level`                                 int comment '报警级别',
    `alarm_sign`                                  int comment '通用报警标志',
    `custom_battery_alarm_count`                  int comment '可充电储能装置故障总数N1',
    `custom_battery_alarm_list`                   array<int> comment '可充电储能装置故障代码列表',
    `custom_motor_alarm_count`                    int comment '驱动电机故障总数N2',
    `custom_motor_alarm_list`                     array<int> comment '驱动电机故障代码列表',
    `custom_engine_alarm_count`                   int comment '发动机故障总数N3',
    `custom_engine_alarm_list`                    array<int> comment '发动机故障代码列表',
    `other_alarm_count`                           int comment '其他故障总数N4',
    `other_alarm_list`                            array<int> comment '其他故障代码列表',
    `battery_count`                               int comment '单体电池总数',
    `battery_pack_count`                          int comment '单体电池包总数',
    `battery_voltages`                            array<int> comment '单体电池电压值列表',
    `battery_temperature_probe_count`             int comment '单体电池温度探针总数',
    `battery_pack_temperature_count`              int comment '单体电池包总数',
    `battery_temperatures`                        array<int> comment '单体电池温度值列表',
    `timestamp`                                   bigint comment '日志采集时间'
) 
    comment '整车日志表'
    partitioned by (`dt` string comment '统计日期')
    ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.JsonSerDe'
    location '/warehouse/car_data/ods/ods_car_data_inc';

```

- 然后映射数据到表中


**注意：1.不准直接把日志数据通过HDFS可视化复制到——/warehouse/car_data/ods/ods_car_data_inc**

因为这里涉及到元数据问题——即粘贴过来的数据没有元数据。

分区——就是一张表多个目录。



**2.错误操作：**

```
load data inpath '/origin_data/car_data_full/2023-07-26' into table ods_car_data_inc;
```

没有设置分区，引擎会走MR。数据格式被改变。



**正确操作：（对原有数据进行剪切操作，并且创建对应分区的元数据）**

```
load data inpath '/origin_data/car_data_full/2023-07-26' into table ods_car_data_inc partition (dt='2023-07-26');
```

成功：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230806202657491.png" alt="image-20230806202657491" style="zoom:33%;" />

/origin_data/car_data_full/2023-07-26被替换到了：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230806202932230.png" alt="image-20230806202932230" style="zoom:25%;" />

如果你把该表删除，再创建的时候，发现数据没了，这时候可以通过修复元数据的方式来解决：（前提是文件夹数据还存在）：

```
--修复hive表的元数据
msck repair table ods_car_data_inc;
```

hive元数据：就是表的属性数据，表的名字，列信息，分区等标的属性信息





#### 2.生成汽车信息表（全量表）

这里还是以2023-07-26的数据为例

**数据格式：按\t（空格分开的数据）**

- 创建表格

```
drop table if exists ods_car_info_full;
create external table ods_car_info_full
(
    `id`               string comment '车辆唯一编码',
    `type_id`          string comment '车型ID',
    `type`             string comment '车型',
    `sale_type`        string comment '销售车型',
    `trademark`        string comment '品牌',
    `company`          string comment '厂商',
    `seating_capacity` int comment '准载人数',
    `power_type`       string comment '车辆动力类型',
    `charge_type`      string comment '车辆支持充电类型',
    `category`         string comment '车辆分类',
    `weight_kg`        int comment '总质量（kg）',
    `warranty`         string comment '整车质保期（年/万公里）'
) comment '整车信息表'
    partitioned by (`dt` string comment '统计日期')
    row format delimited fields terminated by '\t'
    null defined as ''
    location '/warehouse/car_data/ods/ods_car_info_full';

```

这里注意：

hive里面默认控制null为‘\N’，而datax同步过来的控制默认为''空字符串。所以null defined as ''该语句是用于识别空值的。

**分区——一张表不同分区不同数据**。分区表实际上就是对应一个HDFS文件系统上的独立的文件夹，该文件夹下是该分区所有的数据文件。Hive中的分区就是分目录，把一个大的数据集根据业务需要分割成小的数据集。

- 加载数据

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230806205349778.png" alt="image-20230806205349778" style="zoom:33%;" />



#### 3.设置脚本把数据转移到ODS层

在lchen/bin下创建hdfs_to_ods.sh

```
#!/bin/bash

APP='default'

# 判断第二个参数是否填写  如果填写使用作为日期 如果没有填写 默认使用昨天作为日期
if [ -n "$2" ]; then
	#statements
	do_date=$2
else
	do_date=`date -d '-1 day' +%F`
fi



case "$1" in
	"ods_car_data_inc" )
hive -e "load data inpath '/origin_data/car_data_full/$do_date' into table $APP.ods_car_data_inc partition (dt='$do_date');"
		;;
	"ods_car_info_full" )
hive -e "load data inpath '/origin_data/car_info_full/$do_date' into table $APP.ods_car_info_full partition (dt='$do_date');"
		;;
	"all" )
hive -e "load data inpath '/origin_data/car_data_full/$do_date' into table $APP.ods_car_data_inc partition (dt='$do_date');
	load data inpath '/origin_data/car_info_full/$do_date' into table  $APP.ods_car_info_full partition (dt='$do_date');"
		;;
esac

```

注意：数据库别写错了。

赋予权限：

```
sudo chmod 777 hdfs_to_ods.sh 
```

之前我们导入的是7-26号的数据，现在我们利用脚本将27号的汽车数据+日志数据全部导入那两张表：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230806212350125.png" alt="image-20230806212350125" style="zoom:33%;" />

成功：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230806212814241.png" alt="image-20230806212814241" style="zoom:25%;" />

回到HDFS中的origin_data查看，发现27号的数据+日志数据都被转移到/warehouse/car_data/ods下：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230806212921722.png" alt="image-20230806212921722" style="zoom:33%;" />

这个时候我们就可以通过分区查看从表中查看27号的数据：

```
--日志数据
select * from ods_car_data_inc
where dt='2023-07-27';

--汽车数据
--查看数据
select * from ods_car_info_full
where dt='2023-07-27';
```

以27号日志为例，都能输出：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230806213315220.png" alt="image-20230806213315220" style="zoom:33%;" />





### （4）公共维度层（DIM）搭建

记录事务的环境信息，例如汽车行驶过程中的环境数据等。

设计要点：

- 该层存储维度模型的维度表
- DIM层的数据存储格式为orc列式存储+snappy压缩（让select查询速度更快）
- DIM层表名的命名规范为dim_表名_全量表或者拉链表标识（full/zip）



列式存储相比行式存储的优点：

列存更有利于数据的分析计算（OLAP模型），行存有利于增删改查



#### 1.汽车信息维度表导入

建表：

```
drop table if exists dim_car_info_full;
create external table dim_car_info_full
(
    `id`               string comment '车辆唯一编码',
    `type_id`          string comment '车型ID',
    `type`             string comment '车型',
    `sale_type`        string comment '销售车型',
    `trademark`        string comment '品牌',
    `company`          string comment '厂商',
    `seating_capacity` int comment '准载人数',
    `power_type`       string comment '车辆动力类型',
    `charge_type`      string comment '车辆支持充电类型',
    `category`         string comment '车辆分类',
    `weight_kg`        int comment '总质量（kg）',
    `warranty`         string comment '整车质保期（年/万公里）'
) comment '车辆信息维度表'
    partitioned by (`dt` string comment '统计日期')
    stored as orc
    location '/warehouse/car_data/dim/dim_car_info_full'
    tblproperties ('orc.compress' = 'snappy');

```



#### 2.加载数据

一般只需要最新的数据即可。

```
--装载数据进入维度表（同步最新一天的全量数据即可）
insert overwrite table dim_car_info_full partition (dt='2023-07-27')
select
    `id`,
    `type_id`,
    `type`,
    `sale_type`,
    `trademark`,
    `company`,
    `seating_capacity`,
    `power_type`,
    `charge_type`,
    `category` ,
    `weight_kg`,
    `warranty`
    from ods_car_info_full
    where dt='2023-07-27';
```





#### 3.日志编码维度表

额外的离线对照表格。

```
drop table if exists dim_code_full;
create external table dim_code_full
(
    `type`               string comment '编码类型',
    `code_id`          string comment '编码ID',
`code_name`             string comment '编码名称'
) comment '日志编码维度表'
 stored as orc
location '/warehouse/car_data/dim/dim_code_full'
tblproperties ('orc.compress' = 'snappy');

```

编码表啥意思呢？

**例如汽车状态，电池情况可能用12345来表示。然后12345分别代表啥意思就通过编码表对照才知道。**



#### 4.导入编码表数据

这里面存在一个问题，编码表是以orc格式存储+snappy格式压缩的。这就使得无法和数据对应（格式不一样）

- 创建一张临时表格

```
drop table if exists tmp_code_full;
create external table tmp_code_full
(
    `type`               string comment '编码类型',
    `code_id`          string comment '编码ID',
`code_name`             string comment '编码名称'
) comment '日志编码维度表'
row format delimited
fields terminated by '\t'
location '/warehouse/car_data/tmp/tmp_code_full';

```

- 把文件上传到临时表的目录下（通过HDFS的Web界面，数据文件在资料里）

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230807160340884.png" alt="image-20230807160340884" style="zoom:25%;" />

- 把临时表数据写入编码表中

```
--3.把临时表的数据加载到编码表
insert into table dim_code_full
select * from tmp_code_full;
```

- 查看编码表是否加载数据成功

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230807160924481.png" alt="image-20230807160924481" style="zoom:25%;" />





#### 5.dim层数据加载脚本

操作一样：lchen/bin目录下——创建文件ods_to_dim.sh——赋予权限

注意：数据库不要写错了：

```
#!/bin/bash

APP='default'

if [ -n "$2" ]; then
    do_date=$2
else
    do_date=$(date -d '-1 day' +%F)
fi

dim_car_info_full="
insert overwrite table ${APP}.dim_car_info_full partition (dt = '$do_date')
select id,
       type_id,
       type,
       sale_type,
       trademark,
       company,
       seating_capacity,
       power_type,
       charge_type,
       category,
       weight_kg,
       warranty
from ${APP}.ods_car_info_full o
where o.dt = '$do_date';
"

case $1 in
'dim_car_info_full')
    hive -e "${dim_car_info_full}"
    ;;
"all")
    hive -e "${dim_car_info_full}"
    ;;
esac
```

赋予权限：

```
[lchen@hadoop102 bin]$ sudo chmod 777 ods_to_dim.sh 
```

使用：

和ods层脚本逻辑差不多一样。（把ods层对应分区数据——>dim层对应分区数据）不过没有动日志数据，动的是汽车数据信息。

注意：你的dim表用的是overwrite，所以可以重复运行

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230807162434114.png" alt="image-20230807162434114" style="zoom:33%;" />

成功：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230807163344705.png" alt="image-20230807163344705" style="zoom:33%;" />





### （5）明细数据层（DWD）搭建

注意存储事实表，事实表记录业务的过程

事实表的特点——细长。即列少行多

建模理论：

- 存储维度模型的事实表
- 存储格式是orc列式存储+snappy压缩
- DWD层表名的命名规范为dwd_数据域_表名_单分区增量全量标识（inc/full）



#### 1.事实表分类

1. 事务事实表（使用这个）——事务性事实表通常用一条记录表示某个时间点发生的事件或行为。
2. 周期快照事实表
3. 累计快照事实表



**事务事实表的设计流程：**

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230807184721677.png" alt="image-20230807184721677" style="zoom:33%;" />

1. 选择业务过程
2. 声明粒度（粒度——事实表一行表示什么，尽量选择最细粒度）
3. 确认维度
4. 确认事实



#### 2.电动模式行驶日志实现表的装载

建表：（提取出电动模式形式的相关属性）

```
drop table if exists dwd_car_running_electricity_inc;
create external table dwd_car_running_electricity_inc
(
    `vin`                                         string comment '汽车唯一ID',
    `velocity`                                    int comment '车速',
    `mileage`                                     int comment '里程',
    `voltage`                                     int comment '总电压',
    `electric_current`                            int comment '总电流',
    `soc`                                         int comment 'SOC',
    `dc_status`                                   int comment 'DC-DC状态',
    `gear`                                        int comment '挡位',
    `insulation_resistance`                       int comment '绝缘电阻',
    `motor_count`                                 int comment '驱动电机个数',
    `motor_list`                                  array<struct<`id` :int, `status` :int, `rev` :int, `torque` :int,
                                                               `controller_temperature` :int, `temperature` :int,
                                                               `voltage`
                                                               :int, `electric_current` :int>> comment '驱动电机列表',
    `fuel_cell_dc_status`                         int comment '高压DC-DC状态',
    `engine_status`                               int comment '发动机状态',
    `crankshaft_speed`                            int comment '曲轴转速',
    `fuel_consume_rate`                           int comment '燃料消耗率',
    `max_voltage_battery_pack_id`                 int comment '最高电压电池子系统号',
    `max_voltage_battery_id`                      int comment '最高电压电池单体代号',
    `max_voltage`                                 int comment '电池单体电压最高值',
    `min_temperature_subsystem_id`                int comment '最低电压电池子系统号',
    `min_voltage_battery_id`                      int comment '最低电压电池单体代号',
    `min_voltage`                                 int comment '电池单体电压最低值',
    `max_temperature_subsystem_id`                int comment '最高温度子系统号',
    `max_temperature_probe_id`                    int comment '最高温度探针号',
    `max_temperature`                             int comment '最高温度值',
    `min_voltage_battery_pack_id`                 int comment '最低温度子系统号',
    `min_temperature_probe_id`                    int comment '最低温度探针号',
    `min_temperature`                             int comment '最低温度值',
    `battery_count`                               int comment '单体电池总数',
    `battery_pack_count`                          int comment '单体电池包总数',
    `battery_voltages`                            array<int> comment '单体电池电压值列表',
    `battery_temperature_probe_count`             int comment '单体电池温度探针总数',
    `battery_pack_temperature_count`              int comment '单体电池包总数',
    `battery_temperatures`                        array<int> comment '单体电池温度值列表',
    `timestamp`                                   bigint comment '日志采集时间'
)
comment '电动模式行驶日志事实表'
partitioned by (`dt` string comment '统计日期')
stored as orc
location '/warehouse/car_data/dwd/dwd_car_running_electricity_inc'
tblproperties ('orc.compress' = 'snappy');

```

数据装载：（这里采用动态分区）【首日装载】

```
--加载数据

insert overwrite table default.dwd_car_running_electricity_inc partition(dt)
select
    `vin`,
    `velocity`,
    `mileage`,
    `voltage`,
    `electric_current`,
    `soc`,
    `dc_status`,
    `gear`,
    `insulation_resistance`,
    `motor_count`,
    `motor_list`,
    `fuel_cell_dc_status`,
    `engine_status`,
    `crankshaft_speed`,
    `fuel_consume_rate`  ,
    `max_voltage_battery_pack_id`,
    `max_voltage_battery_id`,
    `max_voltage`,
    `min_temperature_subsystem_id`,
    `min_voltage_battery_id`,
    `min_voltage`,
    `max_temperature_subsystem_id`,
    `max_temperature_probe_id`,
    `max_temperature`,
    `min_voltage_battery_pack_id`,
    `min_temperature_probe_id`,
    `min_temperature`,
    `battery_count`,
    `battery_pack_count`,
    `battery_voltages`,
    `battery_temperature_probe_count`,
    `battery_pack_temperature_count`,
    `battery_temperatures`,
    `timestamp`
from default.ods_car_data_inc
where dt <='2023-07-27'
and car_status=1
and execution_mode=1;  
```

这里限制了:

dt <='2023-07-27' and

car_status=1
and execution_mode=1;  

即要求汽车正在行驶，而且模式是存电动。

**动态分区：**

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230808170117220.png" alt="image-20230808170117220" style="zoom:25%;" />

注意Hive不允许一级分区下的动态分区——hive的分区就是分文件夹

解决方案——关闭严格模式：

```
set hive.exec.dynamic.partition.mode=nonstrict;
```

为什么会有一个严格模式：避免一级目录下出现太多的数据（会造成覆盖），举个例子：

假设我昨天导入了上个月的数据，今天我要导入这个月的数据（如果里面混合了上个月的dt）。我采用动态分区，我的表还是overwrite，一旦执行上个月的数据就会被这个月覆盖掉。（这里由于是首次加载故不存在这样的问题，否则就要限定dt的值）。同时遍历所有的dt消耗大量的资源



**报错了：注意表前面可能要加——数据库.**

成功：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230808195804480.png" alt="image-20230808195804480" style="zoom:50%;" />



**每日装载：（正常加载就行）**

```
insert overwrite table default.dwd_car_running_electricity_inc partition(dt='2023-05-03')
select
    `vin`,
    `velocity`,
    `mileage`,
    `voltage`,
    `electric_current`,
    `soc`,
    `dc_status`,
    `gear`,
    `insulation_resistance`,
    `motor_count`,
    `motor_list`,
    `fuel_cell_dc_status`,
    `engine_status`,
    `crankshaft_speed`,
    `fuel_consume_rate`  ,
    `max_voltage_battery_pack_id`,
    `max_voltage_battery_id`,
    `max_voltage`,
    `min_temperature_subsystem_id`,
    `min_voltage_battery_id`,
    `min_voltage`,
    `max_temperature_subsystem_id`,
    `max_temperature_probe_id`,
    `max_temperature`,
    `min_voltage_battery_pack_id`,
    `min_temperature_probe_id`,
    `min_temperature`,
    `battery_count`,
    `battery_pack_count`,
    `battery_voltages`,
    `battery_temperature_probe_count`,
    `battery_pack_temperature_count`,
    `battery_temperatures`,
    \`timestamp\`
from default.ods_car_data_inc
where dt='2023-05-03'
and car_status=1
and execution_mode=1;
```



#### 3.混合模式行驶日志实现表的装载

建表：

```
drop table if exists dwd_car_running_hybrid_inc;
create external table dwd_car_running_hybrid_inc
(
    `vin`                                         string comment '汽车唯一ID',
    `velocity`                                    int comment '车速',
    `mileage`                                     int comment '里程',
    `voltage`                                     int comment '总电压',
    `electric_current`                            int comment '总电流',
    `soc`                                         int comment 'SOC',
    `dc_status`                                   int comment 'DC-DC状态',
    `gear`                                        int comment '挡位',
    `insulation_resistance`                       int comment '绝缘电阻',
    `motor_count`                                 int comment '驱动电机个数',
    `motor_list`                                  array<struct<`id` :int, `status` :int, `rev` :int, `torque` :int,
                                                               `controller_temperature` :int, `temperature` :int,
                                                               `voltage`
                                                               :int, `electric_current` :int>> comment '驱动电机列表',
    `fuel_cell_dc_status`                         int comment '高压DC-DC状态',
    `engine_status`                               int comment '发动机状态',
    `crankshaft_speed`                            int comment '曲轴转速',
    `fuel_consume_rate`                           int comment '燃料消耗率',
    `max_voltage_battery_pack_id`                 int comment '最高电压电池子系统号',
    `max_voltage_battery_id`                      int comment '最高电压电池单体代号',
    `max_voltage`                                 int comment '电池单体电压最高值',
    `min_temperature_subsystem_id`                int comment '最低电压电池子系统号',
    `min_voltage_battery_id`                      int comment '最低电压电池单体代号',
    `min_voltage`                                 int comment '电池单体电压最低值',
    `max_temperature_subsystem_id`                int comment '最高温度子系统号',
    `max_temperature_probe_id`                    int comment '最高温度探针号',
    `max_temperature`                             int comment '最高温度值',
    `min_voltage_battery_pack_id`                 int comment '最低温度子系统号',
    `min_temperature_probe_id`                    int comment '最低温度探针号',
    `min_temperature`                             int comment '最低温度值',
    `battery_count`                               int comment '单体电池总数',
    `battery_pack_count`                          int comment '单体电池包总数',
    `battery_voltages`                            array<int> comment '单体电池电压值列表',
    `battery_temperature_probe_count`             int comment '单体电池温度探针总数',
    `battery_pack_temperature_count`              int comment '单体电池包总数',
    `battery_temperatures`                        array<int> comment '单体电池温度值列表',
    `timestamp`                                   bigint comment '日志采集时间'
)
comment '混动模式行驶日志事实表'
partitioned by (`dt` string comment '统计日期')
stored as orc
location '/warehouse/car_data/dwd/dwd_car_running_hybrid_inc'
tblproperties ('orc.compress' = 'snappy');

```

剩下的数据导入（包括首日和每日）内容逻辑和上面是一样的：

这里只写出首次加载：

```
--数据首次加载
set hive.exec.dynamic.partition.mode=nonstrict;
insert overwrite table default.dwd_car_running_hybrid_inc partition(dt)
select
    `vin`,
    `velocity`,
    `mileage`,
    `voltage`,
    `electric_current`,
    `soc`,
    `dc_status`,
    `gear`,
    `insulation_resistance`,
    `motor_count`,
    `motor_list`,
    `fuel_cell_dc_status`,
    `engine_status`,
    `crankshaft_speed`,
    `fuel_consume_rate`  ,
    `max_voltage_battery_pack_id`,
    `max_voltage_battery_id`,
    `max_voltage`,
    `min_temperature_subsystem_id`,
    `min_voltage_battery_id`,
    `min_voltage`,
    `max_temperature_subsystem_id`,
    `max_temperature_probe_id`,
    `max_temperature`,
    `min_voltage_battery_pack_id`,
    `min_temperature_probe_id`,
    `min_temperature`,
    `battery_count`,
    `battery_pack_count`,
    `battery_voltages`,
    `battery_temperature_probe_count`,
    `battery_pack_temperature_count`,
    `battery_temperatures`,
    `timestamp`,
    `dt`
from default.ods_car_data_inc
where dt <= '2023-07-27'
and car_status=1
and execution_mode=2;
```

成功：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230808202136973.png" alt="image-20230808202136973" style="zoom:33%;" />









#### 4.燃料模式汽车行驶日志事实表

建表：

```
--燃料模式汽车行驶日志事实表
Drop table if exists dwd_car_running_fuel_inc;
create external table dwd_car_running_fuel_inc
(
    `vin`                                         string comment '汽车唯一ID',
    `velocity`                                    int comment '车速',
    `mileage`                                     int comment '里程',
    `voltage`                                     int comment '总电压',
    `electric_current`                            int comment '总电流',
    `soc`                                         int comment 'SOC',
    `dc_status`                                   int comment 'DC-DC状态',
    `gear`                                        int comment '挡位',
    `insulation_resistance`                       int comment '绝缘电阻',
    `fuel_cell_voltage`                           int comment '燃料电池电压',
    `fuel_cell_current`                           int comment '燃料电池电流',
    `fuel_cell_consume_rate`                      int comment '燃料消耗率',
    `fuel_cell_temperature_probe_count`           int comment '燃料电池温度探针总数',
    `fuel_cell_temperature`                       int comment '燃料电池温度值',
    `fuel_cell_max_temperature`                   int comment '氢系统中最高温度',
    `fuel_cell_max_temperature_probe_id`          int comment '氢系统中最高温度探针号',
    `fuel_cell_max_hydrogen_consistency`          int comment '氢气最高浓度',
    `fuel_cell_max_hydrogen_consistency_probe_id` int comment '氢气最高浓度传感器代号',
    `fuel_cell_max_hydrogen_pressure`             int comment '氢气最高压力',
    `fuel_cell_max_hydrogen_pressure_probe_id`    int comment '氢气最高压力传感器代号',
    `fuel_cell_dc_status`                         int comment '高压DC-DC状态',
    `engine_status`                               int comment '发动机状态',
    `crankshaft_speed`                            int comment '曲轴转速',
    `fuel_consume_rate`                           int comment '燃料消耗率',
    `max_voltage_battery_pack_id`                 int comment '最高电压电池子系统号',
    `max_voltage_battery_id`                      int comment '最高电压电池单体代号',
    `max_voltage`                                 int comment '电池单体电压最高值',
    `min_temperature_subsystem_id`                int comment '最低电压电池子系统号',
    `min_voltage_battery_id`                      int comment '最低电压电池单体代号',
    `min_voltage`                                 int comment '电池单体电压最低值',
    `max_temperature_subsystem_id`                int comment '最高温度子系统号',
    `max_temperature_probe_id`                    int comment '最高温度探针号',
    `max_temperature`                             int comment '最高温度值',
    `min_voltage_battery_pack_id`                 int comment '最低温度子系统号',
    `min_temperature_probe_id`                    int comment '最低温度探针号',
    `min_temperature`                             int comment '最低温度值',
    `timestamp`                                   bigint comment '日志采集时间'
)
comment '新能源燃料模式行驶日志事实表'
partitioned by (`dt` string comment '统计日期')
stored as orc
location '/warehouse/car_data/dwd/dwd_car_running_fuel_inc'
tblproperties ('orc.compress' = 'snappy');
```

首日/每日加载数据——逻辑都是一样的。但是由于事务不一样，属性和where删选也就可能不一样：

```
--加载数据
insert overwrite table dwd_car_running_fuel_inc partition(dt)
select
    `vin`,
    `velocity`,
    `mileage`,
    `voltage`,
    `electric_current`,
    `soc`,
    `dc_status`,
    `gear`,
    `insulation_resistance`,
    `fuel_cell_voltage`,
    `fuel_cell_current`,
    `fuel_cell_consume_rate`,
    `fuel_cell_temperature_probe_count`,
    `fuel_cell_temperature`,
    `fuel_cell_max_temperature`,
    `fuel_cell_max_temperature_probe_id`,
    `fuel_cell_max_hydrogen_consistency`,
    `fuel_cell_max_hydrogen_consistency_probe_id`,
    `fuel_cell_max_hydrogen_pressure`,
    `fuel_cell_max_hydrogen_pressure_probe_id`,
    `fuel_cell_dc_status`,
    `engine_status`,
    `crankshaft_speed`,
    `fuel_consume_rate`,
    `max_voltage_battery_pack_id`,
    `max_voltage_battery_id`,
    `max_voltage`,
    `min_temperature_subsystem_id`,
    `min_voltage_battery_id`,
    `min_voltage`,
    `max_temperature_subsystem_id`,
    `max_temperature_probe_id`,
    `max_temperature`,
    `min_voltage_battery_pack_id`,
    `min_temperature_probe_id`,
    `min_temperature`,
    `timestamp`,
    dt
from ods_car_data_inc
where dt<='2023-07-27'
and car_status=1
and execution_mode=3;
```

成功：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230808203430813.png" alt="image-20230808203430813" style="zoom:25%;" />







#### 5.充电桩充电日志事实表

前面都是汽车行驶过程中的日志事实表，其事务是行驶，这里的事务是——充电

这里要注意的是，充电分为4个状态：

- 充电中
- 行驶时充电（过滤掉，严格意义上来说不叫使用充电桩充电）
- 没充电（过滤掉）
- 充电完成

注意：对于充电时间的概念——假如汽车从开始充电到电满用了5个小时，事后没有马上拔出充电口，8个小时后才拔出。那么充电时间我们认为是5.



建表：

```
--充电桩充电日志事实表
drop table if exists dwd_car_parking_charging_inc;
create external table dwd_car_parking_charging_inc
(
    `vin`                                         string comment '汽车唯一ID',
    `voltage`                                     int comment '总电压',
    `electric_current`                            int comment '总电流',
    `soc`                                         int comment 'SOC',
    `dc_status`                                   int comment 'DC-DC状态',
    `gear`                                        int comment '挡位',
    `insulation_resistance`                       int comment '绝缘电阻',
    `engine_status`                               int comment '发动机状态',
    `crankshaft_speed`                            int comment '曲轴转速',
    `fuel_consume_rate`                           int comment '燃料消耗率',
    `max_voltage_battery_pack_id`                 int comment '最高电压电池子系统号',
    `max_voltage_battery_id`                      int comment '最高电压电池单体代号',
    `max_voltage`                                 int comment '电池单体电压最高值',
    `min_temperature_subsystem_id`                int comment '最低电压电池子系统号',
    `min_voltage_battery_id`                      int comment '最低电压电池单体代号',
    `min_voltage`                                 int comment '电池单体电压最低值',
    `max_temperature_subsystem_id`                int comment '最高温度子系统号',
    `max_temperature_probe_id`                    int comment '最高温度探针号',
    `max_temperature`                             int comment '最高温度值',
    `min_voltage_battery_pack_id`                 int comment '最低温度子系统号',
    `min_temperature_probe_id`                    int comment '最低温度探针号',
    `min_temperature`                             int comment '最低温度值',
    `battery_count`                               int comment '单体电池总数',
    `battery_pack_count`                          int comment '单体电池包总数',
    `battery_voltages`                            array<int> comment '单体电池电压值列表',
    `battery_temperature_probe_count`             int comment '单体电池温度探针总数',
    `battery_pack_temperature_count`              int comment '单体电池包总数',
    `battery_temperatures`                        array<int> comment '单体电池温度值列表',
    `timestamp`                                   bigint comment '日志采集时间'
)
comment '充电桩充电日志事实表'
partitioned by (`dt` string comment '统计日期')
stored as orc
location '/warehouse/car_data/dwd/dwd_car_parking_charging_inc'
tblproperties ('orc.compress' = 'snappy');
```

首次/每日数据导入——逻辑一样不多追述：

```
--数据导入/加载
insert overwrite table dwd_car_parking_charging_inc partition(dt)
select
    `vin`,
    `voltage`,
    `electric_current`,
    `soc`,
    `dc_status`,
    `gear`,
    `insulation_resistance`,
    `engine_status`,
    `crankshaft_speed`,
    `fuel_consume_rate`,
    `max_voltage_battery_pack_id`,
    `max_voltage_battery_id`,
    `max_voltage`,
    `min_temperature_subsystem_id`,
    `min_voltage_battery_id`,
    `min_voltage`,
    `max_temperature_subsystem_id`,
    `max_temperature_probe_id`,
    `max_temperature`,
    `min_voltage_battery_pack_id`,
    `min_temperature_probe_id`,
    `min_temperature`,
    `battery_count`,
    `battery_pack_count`,
    `battery_voltages`,
    `battery_temperature_probe_count`,
    `battery_pack_temperature_count`,
    `battery_temperatures`,
    `timestamp`,
    dt
from ods_car_data_inc
where dt<='2023-07-27'
and car_status=2
and charge_status=1;
```

成功：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230808205508038.png" alt="image-20230808205508038" style="zoom:25%;" />







#### 6.行驶充电和故障记录日志事实表

- 行驶充电

建表：

```
--行驶充电日志表
drop table if exists dwd_car_running_charging_inc;
create external table dwd_car_running_charging_inc
(
    `vin`                                         string comment '汽车唯一ID',
    `velocity`                                    int comment '车速',
    `mileage`                                     int comment '里程',
    `voltage`                                     int comment '总电压',
    `electric_current`                            int comment '总电流',
    `soc`                                         int comment 'SOC',
    `dc_status`                                   int comment 'DC-DC状态',
    `gear`                                        int comment '挡位',
    `insulation_resistance`                       int comment '绝缘电阻',
    `motor_count`                                 int comment '驱动电机个数',
    `motor_list`                                  array<struct<`id` :int, `status` :int, `rev` :int, `torque` :int,
                                                               `controller_temperature` :int, `temperature` :int,
                                                               `voltage`
                                                               :int, `electric_current` :int>> comment '驱动电机列表',
    `fuel_cell_voltage`                           int comment '燃料电池电压',
    `fuel_cell_current`                           int comment '燃料电池电流',
    `fuel_cell_consume_rate`                      int comment '燃料消耗率',
    `fuel_cell_temperature_probe_count`           int comment '燃料电池温度探针总数',
    `fuel_cell_temperature`                       int comment '燃料电池温度值',
    `fuel_cell_max_temperature`                   int comment '氢系统中最高温度',
    `fuel_cell_max_temperature_probe_id`          int comment '氢系统中最高温度探针号',
    `fuel_cell_max_hydrogen_consistency`          int comment '氢气最高浓度',
    `fuel_cell_max_hydrogen_consistency_probe_id` int comment '氢气最高浓度传感器代号',
    `fuel_cell_max_hydrogen_pressure`             int comment '氢气最高压力',
    `fuel_cell_max_hydrogen_pressure_probe_id`    int comment '氢气最高压力传感器代号',
    `fuel_cell_dc_status`                         int comment '高压DC-DC状态',
    `engine_status`                               int comment '发动机状态',
    `crankshaft_speed`                            int comment '曲轴转速',
    `fuel_consume_rate`                           int comment '燃料消耗率',
    `max_voltage_battery_pack_id`                 int comment '最高电压电池子系统号',
    `max_voltage_battery_id`                      int comment '最高电压电池单体代号',
    `max_voltage`                                 int comment '电池单体电压最高值',
    `min_temperature_subsystem_id`                int comment '最低电压电池子系统号',
    `min_voltage_battery_id`                      int comment '最低电压电池单体代号',
    `min_voltage`                                 int comment '电池单体电压最低值',
    `max_temperature_subsystem_id`                int comment '最高温度子系统号',
    `max_temperature_probe_id`                    int comment '最高温度探针号',
    `max_temperature`                             int comment '最高温度值',
    `min_voltage_battery_pack_id`                 int comment '最低温度子系统号',
    `min_temperature_probe_id`                    int comment '最低温度探针号',
    `min_temperature`                             int comment '最低温度值',
    `battery_count`                               int comment '单体电池总数',
    `battery_pack_count`                          int comment '单体电池包总数',
    `battery_voltages`                            array<int> comment '单体电池电压值列表',
    `battery_temperature_probe_count`             int comment '单体电池温度探针总数',
    `battery_pack_temperature_count`              int comment '单体电池包总数',
    `battery_temperatures`                        array<int> comment '单体电池温度值列表',
    `timestamp`                                   bigint comment '日志采集时间'
)
comment '充电桩充电日志事实表'
partitioned by (`dt` string comment '统计日期')
stored as orc
location '/warehouse/car_data/dwd/dwd_car_running_charging_inc'
tblproperties ('orc.compress' = 'snappy');
```

首次加载：

```
--加载数据
insert overwrite table dwd_car_running_charging_inc partition(dt)
select
    `vin`,
    `velocity`,
    `mileage`,
    `voltage`,
    `electric_current`,
    `soc`,
    `dc_status`,
    `gear`,
    `insulation_resistance`,
    `motor_count`,
    `motor_list`,
    `fuel_cell_voltage`,
    `fuel_cell_current`,
    `fuel_cell_consume_rate`,
    `fuel_cell_temperature_probe_count`,
    `fuel_cell_temperature`,
    `fuel_cell_max_temperature`,
    `fuel_cell_max_temperature_probe_id`,
    `fuel_cell_max_hydrogen_consistency`,
    `fuel_cell_max_hydrogen_consistency_probe_id`,
    `fuel_cell_max_hydrogen_pressure`,
    `fuel_cell_max_hydrogen_pressure_probe_id`,
    `fuel_cell_dc_status`,
    `engine_status`,
    `crankshaft_speed`,
    `fuel_consume_rate`,
    `max_voltage_battery_pack_id`,
    `max_voltage_battery_id`,
    `max_voltage`,
    `min_temperature_subsystem_id`,
    `min_voltage_battery_id`,
    `min_voltage`,
    `max_temperature_subsystem_id`,
    `max_temperature_probe_id`,
    `max_temperature`,
    `min_voltage_battery_pack_id`,
    `min_temperature_probe_id`,
    `min_temperature`,
    `battery_count`,
    `battery_pack_count`,
    `battery_voltages`,
    `battery_temperature_probe_count`,
    `battery_pack_temperature_count`,
    `battery_temperatures`,
    `timestamp`,
    dt
from ods_car_data_inc
where dt<='2023-07-27'
and car_status=1
and charge_status=2;
```

成功：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230808210539282.png" alt="image-20230808210539282" style="zoom:33%;" />





- 故障告警日志事实表

建表与首次加载：（注意过滤出报警等级大于0的）

```
--故障告警日志事实表
drop table if exists dwd_car_alarm_inc;
create external table dwd_car_alarm_inc
(
    `vin`                                         string comment '汽车唯一ID',
    `car_status`                                  int comment '车辆状态',
    `charge_status`                               int comment '充电状态',
    `execution_mode`                              int comment '运行模式',
    `velocity`                                    int comment '车速',
    `mileage`                                     int comment '里程',
    `voltage`                                     int comment '总电压',
    `electric_current`                            int comment '总电流',
    `soc`                                         int comment 'SOC',
    `dc_status`                                   int comment 'DC-DC状态',
    `gear`                                        int comment '挡位',
    `insulation_resistance`                       int comment '绝缘电阻',
    `motor_count`                                 int comment '驱动电机个数',
    `motor_list`                                  array<struct<`id` :int, `status` :int, `rev` :int, `torque` :int,
                                                               `controller_temperature` :int, `temperature` :int,
                                                               `voltage`
                                                               :int, `electric_current` :int>> comment '驱动电机列表',
    `fuel_cell_voltage`                           int comment '燃料电池电压',
    `fuel_cell_current`                           int comment '燃料电池电流',
    `fuel_cell_consume_rate`                      int comment '燃料消耗率',
    `fuel_cell_temperature_probe_count`           int comment '燃料电池温度探针总数',
    `fuel_cell_temperature`                       int comment '燃料电池温度值',
    `fuel_cell_max_temperature`                   int comment '氢系统中最高温度',
    `fuel_cell_max_temperature_probe_id`          int comment '氢系统中最高温度探针号',
    `fuel_cell_max_hydrogen_consistency`          int comment '氢气最高浓度',
    `fuel_cell_max_hydrogen_consistency_probe_id` int comment '氢气最高浓度传感器代号',
    `fuel_cell_max_hydrogen_pressure`             int comment '氢气最高压力',
    `fuel_cell_max_hydrogen_pressure_probe_id`    int comment '氢气最高压力传感器代号',
    `fuel_cell_dc_status`                         int comment '高压DC-DC状态',
    `engine_status`                               int comment '发动机状态',
    `crankshaft_speed`                            int comment '曲轴转速',
    `fuel_consume_rate`                           int comment '燃料消耗率',
    `max_voltage_battery_pack_id`                 int comment '最高电压电池子系统号',
    `max_voltage_battery_id`                      int comment '最高电压电池单体代号',
    `max_voltage`                                 int comment '电池单体电压最高值',
    `min_temperature_subsystem_id`                int comment '最低电压电池子系统号',
    `min_voltage_battery_id`                      int comment '最低电压电池单体代号',
    `min_voltage`                                 int comment '电池单体电压最低值',
    `max_temperature_subsystem_id`                int comment '最高温度子系统号',
    `max_temperature_probe_id`                    int comment '最高温度探针号',
    `max_temperature`                             int comment '最高温度值',
    `min_voltage_battery_pack_id`                 int comment '最低温度子系统号',
    `min_temperature_probe_id`                    int comment '最低温度探针号',
    `min_temperature`                             int comment '最低温度值',
    `alarm_level`                                 int comment '报警级别',
    `alarm_sign`                                  int comment '通用报警标志',
    `custom_battery_alarm_count`                  int comment '可充电储能装置故障总数N1',
    `custom_battery_alarm_list`                   array<int> comment '可充电储能装置故障代码列表',
    `custom_motor_alarm_count`                    int comment '驱动电机故障总数N2',
    `custom_motor_alarm_list`                     array<int> comment '驱动电机故障代码列表',
    `custom_engine_alarm_count`                   int comment '发动机故障总数N3',
    `custom_engine_alarm_list`                    array<int> comment '发动机故障代码列表',
    `other_alarm_count`                           int comment '其他故障总数N4',
    `other_alarm_list`                            array<int> comment '其他故障代码列表',
    `battery_count`                               int comment '单体电池总数',
    `battery_pack_count`                          int comment '单体电池包总数',
    `battery_voltages`                            array<int> comment '单体电池电压值列表',
    `battery_temperature_probe_count`             int comment '单体电池温度探针总数',
    `battery_pack_temperature_count`              int comment '单体电池包总数',
    `battery_temperatures`                        array<int> comment '单体电池温度值列表',
    `timestamp`                                   bigint comment '日志采集时间'
)
comment '故障充电日志事实表'
partitioned by (`dt` string comment '统计日期')
stored as orc
location '/warehouse/car_data/dwd/dwd_car_alarm_inc'
tblproperties ('orc.compress' = 'snappy');


--加载数据
insert overwrite table dwd_car_alarm_inc partition(dt)
select
    `vin`,
    `car_status`,
    `charge_status`,
    `execution_mode`,
    `velocity`,
    `mileage`,
    `voltage`,
    `electric_current`,
    `soc`,
    `dc_status`,
    `gear`,
    `insulation_resistance`,
    `motor_count`,
    `motor_list`,
    `fuel_cell_voltage`,
    `fuel_cell_current`,
    `fuel_cell_consume_rate`,
    `fuel_cell_temperature_probe_count`,
    `fuel_cell_temperature`,
    `fuel_cell_max_temperature`,
    `fuel_cell_max_temperature_probe_id`,
    `fuel_cell_max_hydrogen_consistency`,
    `fuel_cell_max_hydrogen_consistency_probe_id`,
    `fuel_cell_max_hydrogen_pressure`,
    `fuel_cell_max_hydrogen_pressure_probe_id`,
    `fuel_cell_dc_status`,
    `engine_status`,
    `crankshaft_speed`,
    `fuel_consume_rate`,
    `max_voltage_battery_pack_id`,
    `max_voltage_battery_id`,
    `max_voltage`,
    `min_temperature_subsystem_id`,
    `min_voltage_battery_id`,
    `min_voltage`,
    `max_temperature_subsystem_id`,
    `max_temperature_probe_id`,
    `max_temperature`,
    `min_voltage_battery_pack_id`,
    `min_temperature_probe_id`,
    `min_temperature`,
    `alarm_level`,
    `alarm_sign`,
    `custom_battery_alarm_count`,
    `custom_battery_alarm_list`,
    `custom_motor_alarm_count`,
    `custom_motor_alarm_list`,
    `custom_engine_alarm_count`,
    `custom_engine_alarm_list`,
    `other_alarm_count`,
    `other_alarm_list`,
    `battery_count`,
    `battery_pack_count`,
    `battery_voltages`,
    `battery_temperature_probe_count`,
    `battery_pack_temperature_count`,
    `battery_temperatures`,
    `timestamp`,
    dt
from ods_car_data_inc
where dt<='2023-07-27'
and alarm_level>0;
```



#### 7.电机日志事实表(⭐)

与其他事实表有些不同，它的粒度更细

建表：

```
--点击日志事实表
drop table if exists dwd_car_motor_inc;
create external table dwd_car_motor_inc
(
    `vin` string comment '汽车唯一ID',
    `id`  int comment '电机ID',
    `status` int comment '电机状态',
    `rev`  int comment '电机转速',
    `torque`  int comment '电机转矩',
    `controller_temperature`  int comment '电机控制器温度',
    `temperature`  int comment '电机温度',
    `voltage` int comment '电机控制器输入电压',
`electric_current` int comment '电机控制器直流母线电流',
`timestamp`          bigint comment '日志采集时间'
)
comment '驱动电机日志事实表'
partitioned by (`dt` string comment '统计日期')
stored as orc
location '/warehouse/car_data/dwd/dwd_car_motor_inc'
tblproperties ('orc.compress' = 'snappy');
```

加载数据（首日）：

```
set hive.exec.dynamic.partition.mode=nonstrict;
insert overwrite table dwd_car_motor_inc partition(dt)
select
    vin,
    motor.id ,
    motor.status,
    motor.rev,
    motor.torque,
    motor.controller_temperature,
    motor.temperature,
    motor.voltage,
    motor.electric_current,
`timestamp` ,
    dt
from ods_car_data_inc
lateral view explode(motor_list) tmp as motor
where dt<='2023-07-27';
```

**这里注意，解释一下炸裂函数：**

lateral view explode(motor_list) tmp as motor

炸裂的对象是motor_list这个属性，打个比方：

motor_list属性值是[{A},{B}]，炸裂后motor_list不变**出现motor属性**，属性值分两行是分别是{A}和{B}。

**也许画图更好理解：**

这是炸裂前：

| list      |
| --------- |
| ({A},{B}) |
| ({C},{D}) |

这是炸裂后：

| list      | motor |
| --------- | ----- |
| ({A},{B}) | {A}   |
| ({C},{D}) | {B}   |
|           | {C}   |
|           | {D}   |

成功：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230808213432256.png" alt="image-20230808213432256" style="zoom:33%;" />









#### 8.每次/每日装载脚本

首先我们设置Hive开启非严格模式。

```
[lchen@hadoop102 root]$ cd /opt/module/hive/conf/
```

加一行：

```
<!--Hive设置为非严格模式-->
<property>
    <name>hive.exec.dynamic.partition.mode</name>
    <value>nonstrict</value>
</property>
```

然后在lchen/bin下创建脚本文件ods_to_dwd_init.sh（首次）和ods_to_dwd.sh（每次）即可。（太多就不做演示了）

一样的编写脚本——赋能

**注意linux不支持''这个符号，如果出现属性出现歧义需要用——在用\符号+'**

使用方式也是一样的：

```
脚本文件 + 表名/all全部表  +  分区/时间dt
```

例如：

```
[lchen@hadoop102 bin]$ ./ods_to_dwd_init.sh all 2023-07-27
```

报错/进程被杀死： Failed to submit Spark work, please retry later——原因是内存不够用

只有重新试一试（没办法我电脑内存就那么多，下次换电脑用32G的=_=）

成功：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230809154457823.png" alt="image-20230809154457823" style="zoom:33%;" />





### （6）汇总数据层（DWS）的搭建（⭐⭐⭐）

用于存储基础聚合粒度。



#### 1.行程主题（⭐）

**大致逻辑都和“纯电动汽车单次形成汇总表”一样，重点看它**

1. 纯电动汽车单次形成汇总表（重点内容）

2. 汽车单次充电记录汇总表

3. 汽车单日告警记录汇总表

4. 电机信息单日汇总表

   等

**有了之前的经验这里HQL代码不再全部展示，就是建表+导入数据。挑选其中需要注意的。**



- 汽车单次形成汇总表（⭐）


注意点：汽车每30秒形成一条数据，意思是每行就是汽车30秒内的行驶数据。一旦间隔超过30秒则认为本次行程结束

数据装载过滤条件：

```
if((lag(`timestamp`,1,0)over (partition by vin order by `timestamp` ) - `timestamp`) < -60000,1,0) mark
```

**如果当前时间戳减上一行的时间戳大于60秒（就是时间间隔大于60秒）则认定本次行程结束**

**if（A,B,C）语句：如果A是true mark值为B ，如果A为false mark值为C**



##### 该表的装载语法有写下来的必要，这里的属性不全写出来：

首次装载：（每日装载指定分区即可，可以看SQL文件）

```
insert overwrite table dws_electricity_single_trip_detail partition (dt)
select
    concat(vin,'-',min(\`timestamp\`)) id,
    vin,
    min(`timestamp`) start_timestamp,
    max(`timestamp`)`end_timestamp`,
    min(mileage) `start_mileage`,
    max(mileage)`end_mileage`,
    max(soc) `start_soc`,
    min(soc) `end_soc`,
    avg(velocity) `avg_speed`,
    avg(voltage) `car_avg_voltage`,
    avg(electric_current) `car_avg_electric_current`,
    avg(max_temperature) `battery_avg_max_temperature`,
    collect_list(max_temperature)[cast(count(*)/2 as int)]  `battery_mid_max_temperature`,
    avg(min_temperature) `battery_avg_min_temperature`,
    collect_list(min_temperature)[cast(count(*)/2 as int)]` battery_mid_min_temperature`,
    avg(max_voltage) `battery_avg_max_voltage`,
    collect_list(max_voltage)[cast(count(*)/2 as int)]` battery_mid_max_voltage`,
    avg(min_voltage) `battery_avg_min_voltage`,
    collect_list(min_voltage)[cast(count(*)/2 as int)] `battery_mid_min_voltage`,
    dt
from (
     select
      相关属性
        sum(mark)over (partition by vin order by \`timestamp\`) singer_trip
    from (
         select
            相关属性
            if((lag(`timestamp`,1,0)over (partition by vin order by `timestamp` ) - `timestamp`) < -60000,1,0) mark
        from dwd_car_running_electricity_inc
        where dt<='2023-05-02'
    )t1
)t2
group by dt,vin,singer_trip;

```

这里嵌套了整整3张表=_=，6.应该是这5层中最难的部分了。

1. t1表：

   按汽车id分组，按时间戳排序，当前时间-上行数据>60s的mark值为1，否则为0【1意味着进程的结束】

2. t2表：（可以完整的分出每次行程了）

​	继续按汽车id分组，按时间戳排序，不过对mark属性执行了聚合窗口操作（即sun+over语句），mark值相等的行表示同一进程。

​	3.最后select出来的表：

对同一进程的数据继续计算，例如计算该进程的速度等等（这些属性根据建表逻辑可以查看）。然后加载进去

**最后每组行程一致的数据都会聚合成一行，显示的是汽车每个行程的数据**



*注：这里取中位数的逻辑注意一下：

```
collect_list(max_temperature)[cast(count(*)/2 as int)] 
```

collect_list：把某列属性全收集起来

[cast(count(*)/2 as int)]——就是取中间序列的数据，这里注意数据类型强制转换为int



##### 成功：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230812210013806.png" alt="image-20230812210013806" style="zoom:33%;" />

逻辑不足：注意我们是按日期分区操作的，那么我们这个搭建逻辑就没有考虑到开夜班车的人呐。等于一个人开夜车从23：00开到3：00，数据被拆分成了两个行程，但事实上是一个行程（关于这一点后面我们有解决逻辑）



- 纯电动汽车单次形成汇总表

判断单词的逻辑也是上下时间戳不超过60s，逻辑和上一个表一致。

成功：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230812214717556.png" alt="image-20230812214717556" style="zoom:25%;" />



##### 在虚拟机添加加载这两张表的脚本（包括首次/每日加载）即单次数据的汇总，方便dwd——dws的写入。

dwd_to_dws_single_init.sh和dwd_to_dws_single.sh。详情可以到lchen/bin目录下查看。

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230812220033722.png" alt="image-20230812220033722" style="zoom:25%;" />





- 汽车单日行驶情况

需要注意的是“急加减速”这个属性的计算：

相邻两行速度相差大于500（即50km/h）就算急加/减速。（额，30秒内上下50km/h很正常吧，这里一位是30秒记录一次有点不正常=_=）

注意：运行过程中可能会被杀死进程（受电脑硬件资源影响，内存小了没办法）

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230813110612519.png" alt="image-20230813110612519" style="zoom:25%;" />



- 单日报警累计表和单日信息表

这没啥好说的。sum聚合就行了

结果：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230813111837044.png" alt="image-20230813111837044" style="zoom:25%;" />

一天100多次警报？这数据生成脚本属实是一派胡言=_=

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230813113447786.png" alt="image-20230813113447786" style="zoom:33%;" />



- 单日电池组使用情况表（⭐）

注意：电池的使用会设计两个业务——充电和用电（也就是汽车的充电和行驶）【**所以要用两张表，充电事务表和行驶事务表，实际上需要三张**】

预备冷知识：

新能源汽车的电池正常温度是0~45度。

​	1.注意点1：

存在问题：soc用电量的计算

在每日电池使用中存在：放电——充电——放电这样的过程，因此要计算使用的点亮需要把充电量也算进去才行。故**只用行驶事务表max电-min电的这个逻辑行不通，因为中间可能有充电行为。**

因此我们**需要额外创建一张表来计算电量消耗**（**dws我们不是有单次行程表吗，只要把每次行程的用电量相加就可以得到我们需要的用电情况**）



​	2.注意点2：

存在问题：不存在充电/放电

如果我这辆汽车今天即充电又放电了，那我们直接join3张表就行了。但是如果出现单边情况，比如我今天没出门，所以没放电就出事了——会造成join数据丢失。**于是我们要用满外连接**



设表A，B，C分别是处理后的单日充电表，单日放电表（记录电池温度等），以及单日消耗电量总量表。

则AC内连接，AB全外连接。

大致代码：

```
with t1 as (
    select
       充电属性
    from dwd_car_running_electricity_inc
    where dt<='2023-07-27'
    group by vin,dt
),t2 as (
    select
       放电属性（温度等）
    from dwd_car_parking_charging_inc
    where dt<='2023-05-02'
    group by vin,dt
),t3 as (
    select
        总的耗电数
    from dws_electricity_single_trip_detail
    where dt<='2023-05-02'
    group by vin,dt
)
insert overwrite table dws_car_battery_1d partition(dt)
select
   属性
from t1
full outer join t2
on t1.vin=t2.vin and t1.dt=t2.vin
left join t3
on t1.vin=t3.vin and t1.dt=t3.dt;

```

成功：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230813211156669.png" alt="image-20230813211156669" style="zoom:25%;" />



- 装载每日信息聚合脚本

dwd_to_dws_1d_init.sh和dwd_to_dws_1d.sh

内容一致就不重复了。

成功：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230813212656219.png" alt="image-20230813212656219" style="zoom:25%;" />

可能会在半途被namenode杀掉(计算机内存不够)😂



#### 2.这里用到了窗口函数——hive分析函数：（⭐）

- LAG（col,n,DEFAULT）

用于统计窗口内往上第n行值，**参数1：列名，参数2：往上第n行（默认为1），参数3：null默认值**（若上面第n行没有同一组数据，则设置默认值，否则为null）

例如：

- LEAD（col,n,DEFAULT）


用于统计窗口内往下第n行值。**参数1为列名，参数2为往下第n行（可选，默认为1），参数3为默认值**（若上面第下行没有同一组数据，则设置默认值，否则为null）

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230811210540230.png" alt="image-20230811210540230" style="zoom:25%;" />



##### **这里先了解一下窗口函数，介绍一下：**

1. 首先对窗口函数的理解：

聚合函数——多行聚合成一行

窗口函数——**它最显著的特点就是 OVER 关键字**。既显示聚集前的数据,又要显示聚集后的数据

- 窗口函数的语法：

```
Function() Over (Partition By Column1，Column2，Order By Column3)
这里的Function()可以是：
1. 聚合函数,比如：sum(...)、 max(...)、min(...)、avg(...)等.
2.数据排序函数, 比如 ：rank(...)、row_number(...)等.
3.统计和比较函数, 比如：lead(...)、lag(...)、 first_value(...)等.
```

PARTITION BY 表示将数据先按 字段 进行分区

ORDER BY 表示将各个分区内的数据按 排序字段 进行排序

**例子：**

![image-20230811210104305](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230811210104305.png)





##### 到这里也许分析函数+over窗口函数还是有点不了解

我们举个栗子（以本项目汽车单次形成表为例）：

假设原表：

| 汽车id | 时间戳 |
| ------ | ------ |
| A      | 100    |
| B      | 200    |
| A      | 130    |
| A      | 170    |
| B      | 230    |

```
select * if((lag(`timestamp`,1,0)over (partition by vin order by `timestamp` ) - `timestamp`) > 30,1,0) mark
```

mark行形成逻辑：

1.首先分组——partition by 汽车id，然后排序—— oderby 时间戳

| 汽车id | 时间戳 |
| ------ | ------ |
| A      | 100    |
| A      | 130    |
| A      | 170    |
| B      | 200    |
| B      | 230    |

2.然后执行lag分析函数逻辑

lag的参数：

参数1——显示当前行上n行的哪个属性（时间戳）

参数2——就是n的值（1）

参数3——若第n行超过当前组范围，默认是都是（0）

**一句话翻译就是——mark显示当前组当前行的前一行的时间戳属性值，如果没有前一行则默认值为0**

| 汽车id | 时间戳 | mark |
| ------ | ------ | ---- |
| A      | 100    | 0    |
| A      | 130    | 100  |
| A      | 170    | 130  |
| B      | 200    | 0    |
| B      | 230    | 200  |

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230811212431374.png" alt="image-20230811212431374" style="zoom:33%;" />

**同理，lear函数逻辑相反，指向的是下行的值**



3.然后执行减法操作，当前时间戳-上行的时间戳

| 汽车id | 时间戳 | mark |
| ------ | ------ | ---- |
| A      | 100    | 100  |
| A      | 130    | 30   |
| A      | 170    | 40   |
| B      | 200    | 200  |
| B      | 230    | 30   |

4.最后执行if语句判断，如果当前时间戳-上行时间戳>30则为1，否则为0

| 汽车id | 时间戳 | mark |
| ------ | ------ | ---- |
| A      | 100    | 1    |
| A      | 130    | 0    |
| A      | 170    | 1    |
| B      | 200    | 1    |
| B      | 230    | 0    |

由逻辑数据时间上传超过30秒则视为本行程结束，故A有2个行程B有1个行程：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230811215025960.png" alt="image-20230811215025960" style="zoom:25%;" />

如何表示同一线程，可以用sum把这张表分组求和，同一数字就是同一线程。

![image-20230811215132964](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230811215132964.png)







#### 3.内外连接和全外连接

参考博客：http://lxw1234.com/archives/2015/06/315.htm

内连接，左右连接都好理解。

后者就是根据左/右表的ON变量条件，匹配并结合，匹配不上的属性用null表示。

这里我们主要说全外连接：

全外连接返回所有表中满足where条件的数据，不满足条件的数据以NULL代替：

可以理解为左连接+右连接



内外连接去区别：

**内连接 ：指连接结果仅包含符合连接条件的行，参与连接的两个表都应该符合连接条件。** **外连接 ：连接结果不仅包含符合连接条件的行同时也包含自身不符合条件的行**。

例如：

| 名字  | id   |
| ----- | ---- |
| clx   | 1    |
| barry | 2    |
| q     | 3    |

| id   | salary |
| ---- | ------ |
| 1    | 100    |
| 3    | 200    |
| 4    | 300    |

内连接 on id相同：

| 名字 | id   | salary |
| ---- | ---- | ------ |
| clx  | 1    | 100    |
| q    | 3    | 200    |

**两表都必须满足id相等。**

左外连接 on id相同:

| 名字  | id   | salary |
| ----- | ---- | ------ |
| clx   | 1    | 100    |
| barry | 2    | null   |
| q     | 3    | 200    |

左表完整保留，右表会显示满足id相同的记录，否则为null

同理右外连接也是这样





### （7）数据应用层（ADS）的搭建

就是最终统计观看的需求。

没有使用压缩和存储，这是因为：

1. 结果数据由于是计算完后的结果，所以不会很大
2. ads层数据需要导出



这里注意啊：

不能之间覆盖啊。比如1月的数据你填表了以后，你在insert overwrite 2月的数据1月的就没了。

所以有两种解决方案：

1. 1月的写完马上放到mysql里面或者马上使用
2. overwrite的时候把1月的一起写一遍（这里用的这个方案）



- 每月日程统计表

没啥注意点

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230814173559125.png" alt="image-20230814173559125" style="zoom:25%;" />

- 最近七天统计里程计算

注意：日期的输入只允许有一个。因为如果有两个日期参数，在写shell脚本的时候就很不方便

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230814173656419.png" alt="image-20230814173656419" style="zoom:25%;" />

- 不同类型汽车的每月行程统计

与维度表关联，通过内连接匹配汽车类型

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230816162813074.png" alt="image-20230816162813074" style="zoom:25%;" />

- 每月警告汇总表

  <img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230816163134555.png" alt="image-20230816163134555" style="zoom:25%;" />

- 温控主题每月汇总

电机温度+电池温度

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230816171041761.png" alt="image-20230816171041761" style="zoom:25%;" />

- 每月能耗主题表（⭐⭐难）

**很难，表要分好几个。但是从里往外看能看懂**

快充——平均电流180A以上

慢充——平均电流180A以下

深度充电——电量从小于20%~到80%以上



1. 充电指标属性：


<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230816202400366.png" alt="image-20230816202400366" style="zoom:25%;" />

 两个属性需要计算：

1. mark表示这数据属于第n次充电
2. 每次充电的平均电流



​	2.行程指标属性：（即耗电指标属性）

注意点：

1.在dws层中我们已经实现了电动模式下单次行程汇总表但是遗留了一个问题——**跨天问题**

采用左外连接的连接方式

2.计算最近100km的能耗

**注意：我们的数据生成脚本有点问题：它每次里程的开始里程=结束里程。但是我们还是按照逻辑去算**



最后两表用join合并：



#### 完整代码：

```
with single_trip as (
    select
    vin,
    start_soc, --开始电量
    end_soc,
    start_mileage, --开始时的里程数
    end_mileage,
    start_timestamp, --开始时的时间戳
    end_timestamp,  --结束时的时间戳
    dt
from dws_electricity_single_trip_detail   --存电动模式单次行程汇总表
where substr(dt, 0, 7) = '2023-07'
) ,a0 as (
    select--根据平均电流得到充电模型，展示完整数据(每行代表每月的数据)
    vin,
    '2023-07' mon,
    avg(soc)  soc_per_charge,    --本月所有充电的 平均充电量
    avg(duration)  duration_per_charge, --平均充电时长
    count(*)   charge_count ,--本月充电次数
    sum(`if`(avg_electric>=180,1,0)) fast_charge_count,  --快充次数
    sum(`if`(avg_electric<180,1,0)) slow_charge_count, --慢充次数
    sum(full_charge) fully_charge_count
from(
select--计算平均电流(每行就代表每次的数据)
    vin,
    '2023-07' mon,
    max(soc)-min(soc)  soc,  --每次充电量
    (max(`timestamp`)-min(`timestamp`))/1000  duration,  --每次充电时长(单位是s)
    mark,   --第n次充电次数
    avg(electric_current) avg_electric, --平均电流，用于判断充电类型'
    `if`(min(soc)<=20 and max(soc)>=80,1,0)  full_charge --判断本次sbs'深度充电'

from (select--由时间戳之差计算第n次充电次数（mark）
            vin,
            soc,                                                  --剩余电量
            electric_current,--电流
            `timestamp`,
            sum(`if`(dif_time > 60000, 1, 0)) over (partition by vin order by `timestamp`) mark --判断上下时间戳相差是否大于60s，是:1，否:0。其中1表示是一次新的充电,利用sum函数可表示第几次充电
      from (--基本数据不变，计算时间戳之差
               select vin,
                      soc,                                                                                       --剩余电量
                      electric_current,--电流
                      `timestamp`,
                      `timestamp` - lag(`timestamp`, 1, 0) over (partition by vin order by `timestamp`) dif_time --时间戳之差
               from dwd_car_parking_charging_inc
               where substr(dt, 0, 7) = '2023-07'
               ) a1
      )a2
group by vin,mark
)a3
group by vin
)
insert overwrite table ads_consume_stat_last_month
select *
from ads_consume_stat_last_month
union
select
    a0.vin,
    '2023-07' mon,
    cast(nvl(soc_per_charge,0) as  decimal(16,2)),              --本月所有充电的 平均充电量
    cast(nvl(duration_per_charge,0)as  decimal(16,2)),                                          --本月平均充电时长
    charge_count,
    fast_charge_count,
    slow_charge_count,
    fully_charge_count,
    cast(nvl(soc_per_100km,0)as  decimal(16,2)),
    cast(nvl(soc_per_run,0)as  decimal(16,2)),
    cast(nvl(soc_last_100km,0)as  decimal(16,2))
from (select vin,
             avg(start_soc - end_soc)                                           soc_per_run, --每次里程的平均消耗
             sum(start_soc - end_soc) / sum(end_mileage - start_mileage) * 1000 soc_per_100km, --总能量/总里程=每0.1m的平均耗能，x1000就是每100km的平均耗能
    sum(`if`(dif_of_sum_mileage<1000 and sum_of_mileage>=1000,sum_of_mileage,0))/
    sum(`if`(dif_of_sum_mileage<1000 and sum_of_mileage>=1000,cost_sum_of_soc,0)) *1000  soc_last_100km--最近100km耗能
      from (select vin,
                   start_soc,
                   end_soc,
                   start_mileage,
                   end_mileage,
                   sum_of_mileage,--总里程(动态)
                   cost_sum_of_soc, --总耗电（动态）
                   lag(sum_of_mileage, 1, 0) over (partition by vin order by end_timestamp desc ) dif_of_sum_mileage
            from (select vin,
                         start_soc,
                         end_soc,
                         start_timestamp,
                         end_timestamp,
                         start_mileage,
                         end_mileage,
                         sum(end_mileage - start_mileage)
                             over (partition by vin order by end_timestamp desc ) sum_of_mileage,--总里程(动态)
                         sum(start_soc - end_soc)
                             over (partition by vin order by end_timestamp desc ) cost_sum_of_soc --总耗电（动态）
                  from (select --合并夜班行程数据，并标识冗余数据
                               t1.vin,
                               t1.start_soc    start_soc,                                                                              --开始电量
                               nvl(t2.end_soc, t1.end_soc)                                                 end_soc,--如果存在t2.end_soc说明是夜车，用t2的剩余电流
                               t1.start_mileage,                                                                          --开始时的里程数
                               nvl(t2.end_mileage, t1.end_mileage)                                         end_mileage,
                               t1.start_timestamp,                                                                        --开始时的时间戳
                               nvl(t2.end_timestamp, t1.end_timestamp)                                     end_timestamp, --结束时的时间戳
                               lag(t2.vin, 1, null) over (partition by t1.vin order by t1.start_timestamp) del_mark--删除标记，删除今天第一次数据（因为已经和昨天的合并了）
                        from single_trip t1
                                 left join single_trip t2 --保留一组数据，只
                                           on t1.vin = t2.vin and datediff(t2.dt, t1.dt) = 1 and
                                              t2.start_timestamp - t1.end_timestamp = 30000
--关联条件：1.是同一辆车 2.两天相差1天  3.今天开始时间戳-昨天结束时间戳小于30s——说明属于同一次行程（也就说只有夜车行程才会被关联）
                       ) t3
                  where del_mark is null) t4) t5
      group by vin
)t6 join a0
on t6.vin=a0.vin;


select * from ads_consume_stat_last_month;
```

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230818204313893.png" alt="image-20230818204313893" style="zoom:33%;" />

- 不同汽车类型的平均能耗

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230818204249260.png" alt="image-20230818204249260" style="zoom:33%;" />



同样的配置ads层脚本即可。





## 六.数据导出

- 来到mysql数据库，创建数据库

```
CREATE DATABASE IF NOT EXISTS car_data_report DEFAULT CHARSET utf8mb4 COLLATE utf8mb4_general_ci;
```

- 进入数据库创建表格

具体就不写了，没要点。

一共四张表

1. 里程相关统计
2. 警告相关统计
3. 温控相关统计
4. 能耗相关统计



- 数据导出

工具选用DataX，选用HDFSReader和MySQLWriter。





#### DataX配置文件生成脚本

引言：

前面我们已经知道了datax的基本使用手法，但是如果我要导入多张表到hdfs就需要多个json配置文件，这是很不方便的，所以我们采用脚本的方式，一次性生成多个json配置文件。

1.创建**/opt/module/datax_config_generator/configuration.properties文件**（在资料中复制）

然后修改成：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230819110701094.png" alt="image-20230819110701094" style="zoom: 33%;" />

启动脚本：

```
[lchen@hadoop102 datax_config_generator]$ java -jar datax-config-generator-1.0-SNAPSHOT-jar-with-dependencies.jar 
```

完成：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230819112346413.png" alt="image-20230819112346413" style="zoom:25%;" />



我们尝试一下生成的配置文件好不好用：

```
[lchen@hadoop102 datax]$ python bin/datax.py -p"-Dexportdir=//warehouse/car_data/ads/ads_consume_stat_last_month" job/export/car_data_report.ads_consume_stat_last_month.json

命令格式:
python bin/datax.py -p"-D 参数= +hive表格再hdfs中的路径" + datax配置文件路径

```

成功：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230819113429542.png" alt="image-20230819113429542" style="zoom:25%;" />

可以看到数据成功导入 到了mysql：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230819113504278.png" alt="image-20230819113504278" style="zoom:25%;" />





#### 使用脚本完成数据的导出

在home/lchen/bin下创建hdfs_to_mysql.sh 

```
[lchen@hadoop102 bin]$ sudo vim hdfs_to_mysql.sh 
[lchen@hadoop102 bin]$ sudo chmod 777 hdfs_to_mysql.sh 
[lchen@hadoop102 bin]$ ./hdfs_to_mysql.sh all

```

成功：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230819122044846.png" alt="image-20230819122044846" style="zoom:25%;" />

这样car_data_report的数据就填完了。

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230819122140342.png" alt="image-20230819122140342" style="zoom:25%;" />







## 七.dolphinScheduler（海豚调度器）

分布式，易扩展的可视化DAG工作流任务调度平台。(所谓DAG任务流调度——就是有顺序且有向无环，不能一直重复)

**G，内存要求高。宝宝电脑扛不住了要=_=**



### 1.核心架构

- MasterServer

采用分布式无中心设计理念，主要负责DAG任务的划分，提交，监控，并监听MasterServer和WorkerServer的健康状态

- WorkerServer

也采用分布式无中心设计理念，主要负责任务的执行和提供日志服务

- Zookeeper

MasterServer和WorkerServer通过它进行集群管理和容错

- Alert

提供警告相关服务

- API

主要负责处理前端UI请求

- UI

提供可视化页面



运行模式：

- 单机模式
- 伪分布式模式——该模式下master、worker、api server、logger server等服务都只在同一台机器上
- 分布式模式——与伪集群模式的区别就是在多台机器部署 DolphinScheduler各项服务，并且Master、Worker等服务可配置多个。





集群规划：

| hadoop102 | master、worker |
| --------- | -------------- |
| hadoop103 | worker         |
| hadoop104 | worker         |





### 2.安装部署

1.安装分析工具（三台都要）

```
sudo yum install -y psmisc
```

2.上传安装包至/opt/software并解压到当前目录，此时并不算安装好，这只是一个安装包

```
[lchen@hadoop102 software]$ tar -zxvf apache-dolphinscheduler-2.0.8-bin.tar.gz 
```

3.改变安装包参数，默认是单机模式我们要改一下参数

cd到这个安装包的conf/config

```
vim  install_config.conf 
```

具体内容可以看资料

4.将对应文件拷贝到对应目录

cd 安装包根目录，然后把对应配置复制过来：

```
[lchen@hadoop102 apache-dolphinscheduler-2.0.8-bin]$ sudo cp /opt/module/hadoop/etc/hadoop/core-site.xml conf
[lchen@hadoop102 apache-dolphinscheduler-2.0.8-bin]$ sudo cp /opt/module/hadoop/etc/hadoop/hdfs-site.xml conf

```



5.

海豚调度器会把元数据存到mysql里面，故要创建数据库（安装上面的安装配置文件创建）

```
mysql -uroot -p000000    进入mysql

CREATE DATABASE dolphinscheduler DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;   建库

CREATE USER 'dolphinscheduler'@'%' IDENTIFIED BY 'dolphinscheduler'; 创建用户，并设置密码用户为dolphinscheduler

GRANT ALL PRIVILEGES ON dolphinscheduler.* TO 'dolphinscheduler'@'%';给与该用户操作数据库的权限

flush privileges; 刷新
```



6.

初始化数据库

把mysql连接器给调度器：

```
[lchen@hadoop102 apache-dolphinscheduler-2.0.8-bin]$ sudo sudo cp /opt/software/mysql/mysql-connector-j-8.0.31.jar lib/
```

初始化命令：

```
script/create-dolphinscheduler.sh
```

如图：海豚调度器的元数据数据库也建立完成了：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230823202405952.png" alt="image-20230823202405952" style="zoom:25%;" />

确保zookeeper启动着，然后就可以开始安装了：

```
[lchen@hadoop102 apache-dolphinscheduler-2.0.8-bin]$ ./install.sh 
```

**注意你要使你的hadoop102处于活跃状态。**

安装完成！

UI地址：[http://hadoop104:12345/dolphinscheduler](http://hadoop102:12345/dolphinscheduler)

用户名：admin

密码：dolphinscheduler123

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230823204331239.png" alt="image-20230823204331239" style="zoom:33%;" />





### 3.使用/停止命令

```
[lchen@hadoop102 /]$ cd /opt/module/dolphinscheduler/
[lchen@hadoop102 dolphinscheduler]$ cd bin/
[lchen@hadoop102 bin]$ ./stop-all.sh 
启动就start-all.sh就行了
```

注意：

Master无法启动，查看日志信息——Cannot allocate memory

**即内存不够了！=_=果然，G。**

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230823212543054.png" alt="image-20230823212543054" style="zoom:25%;" />

我已经分配内存了。只能硬着头皮取写，看看能不能继续吧





创建租户：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230824202934718.png" alt="image-20230824202934718" style="zoom:25%;" />

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230824203038186.png" alt="image-20230824203038186" style="zoom:25%;" />

创建用户：

用户名：lchen

密码：lchen123

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230824203216034.png" alt="image-20230824203216034" style="zoom:25%;" />

邮箱填自己的即可



### 4.管理调度任务

推出登陆，用lchen登陆。点击项目管理开始创建项目：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230824203903347.png" alt="image-20230824203903347" style="zoom:25%;" />

创建完后点击这个项目，进入管理平台：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230824204010785.png" alt="image-20230824204010785" style="zoom:25%;" />

这里的操作模块可以类比代码：

工作流定义——声明类

工作流实例——声明对象



#### （1）入门案例：

工作流定义——创建工作流。通过拖拽使用功能

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230824204456334.png" alt="image-20230824204456334" style="zoom:25%;" />

node2/3分别是hello和barry，接下来通过连线设置运行顺序：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230824204828787.png" alt="image-20230824204828787" style="zoom:25%;" />

点击保存，设置名字为test：

![image-20230824205010595](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230824205010595.png)

点击上线+运行：

啊~没有master运行不了。尝试给1号虚拟机加1G内存。

总算调出来了=_=电脑要炸了感觉：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230824211831318.png" alt="image-20230824211831318" style="zoom:25%;" />

**注意：即使如此Master也可能掉线，重启即可。**



点击“工作流实例”：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230824214600884.png" alt="image-20230824214600884" style="zoom: 25%;" />

如果没有，恭喜你内存又不够了。

点击进去发现运行失败，与此同时master又掉了。我们进入日志文件：

```
[lchen@hadoop102 logs]$ tail -200 dolphinscheduler-master.log
```

查看报错信息：

 zookeeper connect timeout 或者current cpu load average 0.75 is too high or available memory 0.07G is too low。

内存还是不够。**经常挂，没办法我们把Hadoop集群关掉缓解压力**



关闭hadoop后内存够用了，再次点击工作流实例，发现运行完成：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230825095812834.png" alt="image-20230825095812834" style="zoom:25%;" />

点击其中一个节点——查看日志，即可查看到输出数据：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230825095928677.png" alt="image-20230825095928677" style="zoom:25%;" />

吐槽：好家伙不开Hadoop也占用这么多呀

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230825100025408.png" alt="image-20230825100025408" style="zoom:25%;" />





#### （2）定时和传参功能

- 定时功能

要求流程调度一天执行一次，要求定时启动。

1.工作流定义——点击定时

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230825100646777.png" alt="image-20230825100646777" style="zoom:33%;" />

2.默认1小时执1次

这里我们设置1分钟1次

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230825103651938.png" alt="image-20230825103651938" style="zoom:25%;" />

查看时间对不对：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230825103715411.png" alt="image-20230825103715411" style="zoom:25%;" />

点击创建即可



3.点击定时管理

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230825103959241.png" alt="image-20230825103959241" style="zoom:25%;" />

点击上线

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230825104034441.png" alt="image-20230825104034441" style="zoom:25%;" />

1分钟后：（数据流实例）

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230825104128410.png" alt="image-20230825104128410" style="zoom:33%;" />

再刷新：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230825104218448.png" alt="image-20230825104218448" style="zoom:25%;" />



- 传参功能

先让工作流定义下线，然后修改编辑

第一种：设置局部参数：（只作用于对应节点）

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230825105916828.png" alt="image-20230825105916828" style="zoom:25%;" />

第二种：设置全局参数（作用于所有节点）

点击保存时会让你设置：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230825110046766.png" alt="image-20230825110046766" style="zoom:25%;" />

**注意：若全局参数和局部参数都设置了，那么默认采用全局参数**



第三种：传递参数

就是上游节点传递给下游

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230825111635769.png" alt="image-20230825111635769" style="zoom:25%;" />

写法：

```
"${setValue{key=value}}"
```

key和value自己编

或者：

把参数类型改成OUT，效果也是一样的。

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230825111447367.png" alt="image-20230825111447367" style="zoom:25%;" />



- 内置参数

| **变量名**             | **参数**              | **说明**                        |
| ---------------------- | --------------------- | ------------------------------- |
| **system.biz.date**    | ${system.biz.date}    | 定时时间前一天，格式为 yyyyMMdd |
| **system.biz.curdate** | ${system.biz.curdate} | 定时时间，格式为 yyyyMMdd       |
| **system.datetime**    | ${system.datetime}    | 定时时间，格式为 yyyyMMddHHmmss |



- 自定义日期格式

可以对 $[yyyyMMddHHmmss] 任意分解组合，如 $[yyyyMMdd], $[HHmmss], $[yyyy-MM-dd]。

例如：

| **参数**                           | **说明** |
| ---------------------------------- | -------- |
| **$[add_months(yyyyMMdd,12\*N)]**  | 后 N 年  |
| **$[add_months(yyyyMMdd,-12\*N)]** | 前 N 年  |
| **$[add_months(yyyyMMdd,N)]**      | 后 N 月  |
| **$[add_months(yyyyMMdd,-N)]**     | 前 N 月  |







#### （3）引用依赖资源和告警功能

为了防止内存不够用，我们只启动HDFS：

```
[lchen@hadoop102 root]$ start-dfs.sh
```



#### 资源依赖

1.首先点击资源中心——创建文件夹“test_shell”

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230825202214611.png" alt="image-20230825202214611" style="zoom:25%;" />

在HDFS里的位置：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230825202200290.png" alt="image-20230825202200290" style="zoom:25%;" />

2.进入文件夹里，点击创建文件

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230825202403479.png" alt="image-20230825202403479" style="zoom:25%;" />



如何在工具流中使用？

点击节点设置资源，再写上相对路径即可

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230825202542196.png" alt="image-20230825202542196" style="zoom:25%;" />





#### 告警通知

即节点运行失败，需要它告诉我们哪里有问题。

1.首先我们切换成admin用户，然后进入安全中心——告警实例管理——“创建告警实例”

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230825205237312.png" alt="image-20230825205237312" style="zoom:25%;" />

填写邮箱信息，其中host信息需要在邮箱中寻找，点击提交即可。









### 5.数仓调度全流程

- 生产数据

关闭海豚调度器，启动zookeeper和HDFS：

```
[lchen@hadoop102 bin]$ start-dfs.sh
```

启动Kafka和两个flume：

```
[lchen@hadoop102 bin]$ ./kf.sh start
[lchen@hadoop102 bin]$ ./fl.sh start
[lchen@hadoop102 bin]$ ./f2.sh start
```

造新的一天数据：

```
[lchen@hadoop102 bin]$ lg.sh 2023-07-28
```

查看数据——直到没有tmp文件就表明上传完毕：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230825210840373.png" alt="image-20230825210840373" style="zoom:25%;" />



接下来启动海豚调度器（为了避免内存不足我们使用单机模式）

```
[lchen@hadoop102 bin]$ cd /opt/module/dolphinscheduler/bin/ 
[lchen@hadoop102 bin]$ ./dolphinscheduler-daemon.sh start standalone-server
```

注意：此时可视化地址变成102了：http://hadoop102:12345/dolphinscheduler/ui/view/login/index.html

我们用lchen登陆



- 脚本上传

在先把脚本放到本地：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230825212558077.png" alt="image-20230825212558077" style="zoom:25%;" />

然后上传到海豚调度器：

资源中心——创建文件夹——进入文件夹——上传文件

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230825212946000.png" alt="image-20230825212946000" style="zoom:25%;" />



- 环境准备

退出，用admin用户登陆

复制虚拟机环境变量：

```
[lchen@hadoop102 bin]$ sudo vim /etc/profile.d/my_env.sh 
```

安全中心——环境管理——创建环境

粘贴环境变量并做如下设置：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230825214607039.png" alt="image-20230825214607039" style="zoom:25%;" />





回到lchen用户

创建项目——car：

项目管理——创建项目——进入指定项目

- 创建工作流

这里以mysql_to_hdfs.sh脚本为例（即把维度数据从mysql通过datax发给HDFS）

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230825222522450.png" alt="image-20230825222522450" style="zoom:25%;" />

把脚本全写出来，如图：

![image-20230825224921872](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230825224921872.png)

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230825220433947.png" alt="image-20230825220433947" style="zoom:50%;" />

**保存的时候记得设置参数dt=2023-07-28**：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230825222559195.png" alt="image-20230825222559195" style="zoom:25%;" />

**上线工作流**



- 启动yarn，运行工作流

```
[lchen@hadoop102 bin]$ start-yarn.sh
```

然后回到海豚调度器。先上线+运行1d工作流后是1m工作流，

运行得很慢，要等一下~

完成：

![image-20230825224836409](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230825224836409.png)

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230826103000490.png" alt="image-20230826103000490" style="zoom:33%;" />



然后数据就覆盖写入到了mysql中：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230826103820314.png" alt="image-20230826103820314" style="zoom:25%;" />







## 八.BI可视化展示

上传，解压，然后用内置脚本上传

```
[lchen@hadoop102 software]$ bash ./linux_unix_FineBI6_0-CN.sh 
```

可视化地址：http://hadoop102:37799/webroot/decision 

**设置密码+账户：全设置为admin**

选择：外接数据库

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230826111851428.png" alt="image-20230826111851428" style="zoom:25%;" />

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230826112510991.png" alt="image-20230826112510991" style="zoom:25%;" />

密码是000000



- 在mysql中创建元数据库

```
CREATE DATABASE `finedb` DEFAULT CHARACTER SET utf8 COLLATE utf8_bin;
```

然后点击“启用新的数据库”，然后登陆即可：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230826140753380.png" alt="image-20230826140753380" style="zoom:33%;" />





- 导入数据

首先连接MySQL

管理系统——数据连接——数据连接管理——新建数据连接——选择MySQL

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230826141130953.png" alt="image-20230826141130953" style="zoom:25%;" />

作如下设置：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230826141239195.png" alt="image-20230826141239195" style="zoom:25%;" />

账号密码都是MySQL的，密码是000000，点击测试连接（右上）——成功后保存



公共数据（左栏）——新建文件夹car_data——新建数据集(选择数据库表)

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230826143100671.png" alt="image-20230826143100671" style="zoom:25%;" />

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230826141704848.png" alt="image-20230826141704848" style="zoom:25%;" />

选择4个数据库表即可：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230826143153629.png" alt="image-20230826143153629" style="zoom:25%;" />







- 分析主题

点击——我的分析（左栏）——新建分析主题

选择四张表格：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230826143850484.png" alt="image-20230826143850484" style="zoom:25%;" />

左下角点击组件





### 1.各汽车报价情况单月统计

使用堆积型柱状图，总长度==一/二/三级告警次数之和==告警次次数

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230826144740933.png" alt="image-20230826144740933" style="zoom:50%;" />

**注意点：换表的时候不要保留字段配置**

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230826144953677.png" alt="image-20230826144953677" style="zoom:25%;" />







### 2.各汽车平均百公里急加减速的次数统计（每月）

加一个组件

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230826145040893.png" alt="image-20230826145040893" style="zoom:50%;" />







### 3.汽车每月电池温度异常统计

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230826145521335.png" alt="image-20230826145521335" style="zoom:50%;" />







### 4.汽车能耗指标

由于数据生成脚本有问题，所以里程为0.故耗能为0

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230826150022350.png" alt="image-20230826150022350" style="zoom:33%;" />







### 5.添加仪表盘

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230826150551656.png" alt="image-20230826150551656" style="zoom:25%;" />















